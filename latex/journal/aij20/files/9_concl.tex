In this paper, we formally defined the problem of step-wise explanation generation for satisfaction problems, as well as presenting a generic algorithm for solving the problem. We extended the mechanism so that it can be used in a \textit{nested} way, to further explain an explanation.
We developed algorithm in the context of logic grid puzzles where we start from natural language clues and provide a human-friendly explanation in the form of a visualisation. 

%There are multiple opportunities for improvements and future work.
%While developing this work, we discovered some potential topics for improvement. 
%We used this implementation to investigate puzzle properties and difficulty. 
%
When investigating the nested explanation in Figure \ref{fig:zebrascreen:path} as it is produced by the system, one can observe that this explanation does not entirely match an explanation that would be produced by a human reasoner for a couple of reasons: 
\begin{itemize}
 \item In the generation of the nested explanation, as well as in the high-level sequence, we used the greedy algorithm from section \ref{sec:expl-gen-prod}. 
 While at the high level, this yields good results, at the nested level, this results in sometimes propagating facts that are not used afterwards. 
 The very first propagation in the nested explanation is of this kind.
 While this would be easy to fix by postprocessing the generated explanation, we left it in our example to highlight this difference between the nested and non-nested explanation. 
 \item It sometimes happens that the system finds, as a minimal explanation, one in which $X-1$ negative facts are used instead of the corresponding single positive fact. This can be seen in the last step. For human reasoners the positive facts often seem to be easier to grasp. A preference for the system towards these negative facts might be incidentally due to formulation of the clues or it can incidentally happen due to the way the MUS is computed (only subset-minimality is guaranteed there). 
 In general, observations of this kind should be taken into account when devising a cost function. 
 \item A last observation we made (but that is not visible in the current figure) is that sometimes the generated nested explanations seem to be unnecessarily hard. In all cases we encountered where that was the case, the explanation was the same: the set of implicit constraints contains a lot of redundant information: a small number of them would be sufficient to imply all the others. Our cost function, and the subset-minimality of the generated MUS entails that in the explanation of a single step, implicit constraints will never be included if they follow from other included implicit constraints. However, when generating the nested explanations, it would actually be preferred to have those redundant constraints, since they allow breaking up the explanation in simpler parts, e.g., giving a simple step with a single bijectivity, rather than a complex step that uses a combination of multiple implicit constraints.
\end{itemize}

\revision{These observations suggest that further research into the question \emph{what constitutes an understandable explanation for humans} is needed with respect to using appropriate interpretability metrics \cite{hoffman2018metrics,rosenfeld2021better}. Additional directions to produce easier-to-understand explanations would be \emph{(i)} to  optimize the sequence as a whole, rather than only individual steps, and \emph{(ii)} to learn the cost function based on user traces.} 

\revision{Additionally, on our puzzles,  the nested explanations were so simple that no further refinement was needed. 
For more difficult problems, this may no longer be the case; as such, a possible avenue for future work is a generic approach to multi-level nested explanations. 
Another interesting direction is to research whether nesting can be related to existing notions of abstraction and refinement \cite{leuschel2005automatic, saribatur2019abstraction, mitchell2008expressive}.}

% Our nested explanations can also be seen as a form of abstraction. More work can be done on further grouping steps, or refining steps, based on feedback of what the user finds \textit{useful}.

With respect to \emph{efficiency}, the main bottleneck of the current algorithm is the many calls to MUS, which is a hard problem by itself. 
For this reason, in the time between submission and acceptance of this paper, we have investigated methods to perform \emph{unsatisfiable subset optimization} \cite{ijcaiexplainingcsps}, building on existing algorithms for searching cardinality-minimal MUSs \cite{ignatiev2015smallest}.

%\bart{REMOVE:
%Therefore, in future work we want to investigate unsat-core \emph{optimization} with respect to a cost-function, either by taking inspiration for instance from the MARCO algorithm~\cite{liffiton2013enumerating} but adapting it to prune based on cost-functions instead of subset-minimality, or alternatively by reduction to quantified Boolean formulas or by using techniques often used there~\cite{QBF,DBLP:journals/constraints/IgnatievJM16}.}
%\bart{REPLACE BY:
%For this reason, in the time between submission and acceptance of this paper, we have investigated methods to perform \emph{unsatisfiable subset optimization} \cite{ijcaipaper}, building on existing algorithms for searching cardinality-minimal MUSs \cite{smus}. \bart{EMILIO, add references}
%}
%\bart{I added the ref to maxQBF here. It seems very strange to not put it here since they do unsat core optimization! But I see a commented-out discussion about fear of giving something away. To be verified.}
%.\emilio{put the ignatiev smallest mus? \cite{ignatiev2015smallest}} No, don't want to give it away... [45, 60, 39, 52]

% Secondly, we want to dig deeper into 
%To illustrate this last point: in the setting of very difficult puzzles, some of the explanation steps still require some effort to understand. 
%When explained by a human, this is often done using some form of proof by contradiction using an explanation of the form ``suppose this [the derived fact] would not hold, then [some simpler reasoning steps], which is not possible''. This is also how we explained Figure \ref{fig:pasta_diff} at the end of Section \ref{sec:nested-explanation}.
%This explanation process is of \emph{exactly the same form} as what we generate now. The only difference is that $I_0$ is not the empty interpretation, but one in which a wrong value is assigned. 

\revision{From a systems point of view, a direction for future work is to make our approach (near) real-time, essentially allowing \ourtool to be called \emph{while} a user is solving the puzzle. 
This will become especially important when we implement our ideas in more serious domains, such as \emph{interactive configuration}, where a human and a search engine cooperate to solve a configuration problem and the human can often be interested in understanding \emph{why} the system did certain derivations \cite{DBLP:journals/tplp/HertumDJD17,DBLP:conf/bnaic/CarbonnelleADVD19}.}

% Finally, we wish to extend the approach so that it is also applicable to \textit{optimisation problems}. An additional challenge is explaining \textit{search} choices on top of propagation steps as we do in this work. Many open questions remain, but key concepts such as a sequence of simple steps and searching for simple explanations based on explanations of individual facts offer interesting starting points.

%\tias{tias adds future work}

% 
% \todo{add some observations for future work:
% \begin{itemize}
%  \item Nested explanation sometimes produces unused things. (max aggregates + greedy)
%  \item Sometimes a nested explanation seems to difficult: could be made easier by using **more** clues, actually thus making the upper step harder. This suggests there might be a new way to define cost based on nested expl. 
%  \item Positive vs negative asymmetry in perceived quality. 
%  \item Heuristic approach; possibility for QBF
% \end{itemize}
% }
