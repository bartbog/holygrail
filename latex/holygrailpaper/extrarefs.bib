@misc{zebra,
   author = "Wikipedia",
   title = "{Zebra Puzzle} --- {W}ikipedia{,} The Free Encyclopedia",
   year = "2017",
   howpublished = {\url{http://en.wikipedia.org/w/index.php?title=Zebra\%20Puzzle&oldid=779870856}},
   note = "[Online; accessed 24-May-2017]"
 }
@article{idp,
  author    = {Broes de Cat and
               Bart Bogaerts and
               Maurice Bruynooghe and
               Marc Denecker},
  title     = {Predicate Logic as a Modelling Language: The {IDP} System},
  journal   = {CoRR},
  volume    = {abs/1401.6312},
  year      = {2014},
  url       = {http://arxiv.org/abs/1401.6312},
  timestamp = {Tue, 26 Aug 2014 10:41:12 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/CatBBD14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@inproceedings{Mikolov2013,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  year={2013}
}
@misc{ACEConstructionRules,
  author = {Fuchs, Norbert E. and Kuhn, Tobias},
  title = {{ACE} 6.7 Construction Rules},
  urldate = {2013-07-31},
  howpublished = {\url{http://attempto.ifi.uzh.ch/site/docs/ace_constructionrules.html}},
  url = {http://attempto.ifi.uzh.ch/site/docs/ace_constructionrules.html}
}
@book{Shieber2003,
author = {Shieber and Stuart, M},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/shieber-uagf-distrib-130816{\_}0.pdf:pdf},
publisher = {Microtome Publishing},
title = {{An Introduction to Unification-Based Approaches to Grammar.}},
year = {2003}
}
@misc{NLPCourse,
  title={Natural Language Processing Techniques in Prolog},
  author={Blackburn, Patrick and Striegnitz, Kristina},
  howpublished = {\url{http://cs.union.edu/~striegnk/courses/nlp-with-prolog/html/index.html}},
  year={2002}
}
@article{Fuchs2008drs,
abstract = {This technical report describes the discourse representation structures (DRS) derived from texts written in version 6.7 of Attempto Controlled English (ACE 6.7). The description is done by a set of examples. Among other things, ACE 6.7 supports modal statements, negation as failure, and sentence subordination. These features require an extended form of discourse representation structures. The discourse representation structure itself uses a reified, or ‘flat' notation, meaning that its atomic conditions are built from a small number of predefined predicates that take constants standing for words of the ACE text as their arguments.},
author = {Fuchs, N.E. E and Kaljurand, Kaarel and Kuhn, Tobias},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/drs{\_}report{\_}65.pdf:pdf},
journal = {Department of Informatics. University of Zurich, Zurich},
mendeley-groups = {CNLs/ACE},
number = {August},
pages = {1--59},
title = {{Discourse representation structures for ace 6.5}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.148.6989{\&}rep=rep1{\&}type=pdf},
volume = {2010},
year = {2008}
}
@article{Blackburn2006,
  title={Working with Discourse Representation Theory},
  author={Blackburn, Patrick and Bos, Johan},
  journal={An Advanced Course in Computational Semantics},
  year={2006}
}

@inproceedings{DRT,
  author    = {Hans Kamp},
  title     = {Discourse Representation Theory: What it is and Where it Ought to
               Go},
  booktitle = {Natural Language at the Computer, Scientific Symposium on Syntax and
               Semantics for Text Processing and Man-Machine-Communication, Heidelberg,
               FRG, February 25, 1988, Proceedings},
  pages     = {84--111},
  year      = {1988},
  crossref  = {DBLP:conf/ibm/1988},
  url       = {https://doi.org/10.1007/3-540-50011-1\_34},
  doi       = {10.1007/3-540-50011-1\_34},
  timestamp = {Tue, 14 May 2019 10:00:54 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/ibm/Kamp88},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@proceedings{DBLP:conf/ibm/1988,
  editor    = {Albrecht Blaser},
  title     = {Natural Language at the Computer, Scientific Symposium on Syntax and
               Semantics for Text Processing and Man-Machine-Communication, Heidelberg,
               FRG, February 25, 1988, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {320},
  publisher = {Springer},
  year      = {1988},
  url       = {https://doi.org/10.1007/3-540-50011-1},
  doi       = {10.1007/3-540-50011-1},
  isbn      = {3-540-50011-1},
  timestamp = {Tue, 14 May 2019 10:00:54 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/ibm/1988},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Book{logigrammen,
 author = {Ryder, Stephen},
 title = {Puzzle Baron's logic puzzles},
 publisher = {Alpha Books},
 year = {2016},
 address = {Indianapolis, Indiana},
 isbn = {9781465454652}
 }

%--------------------
@article{Bos2011,
abstract = {The aim of computational semantics is to capture the meaning of natural language expressions in representations suitable for performing inferences, in the service of understanding human language in written or spoken form. First-order logic is a good starting point, both from the representation and inference point of view. But even if one makes the choice of first-order logic as representa-tion language, this is not enough: the computational semanticist needs to make further decisions on how to model events, tense, modal contexts, anaphora and plural entities. Semantic representa-tions are usually built on top of a syntactic analysis, using unification, techniques from the lambda-calculus or linear logic, to do the book-keeping of variable naming. Inference has many potential applications in computational semantics. One way to implement inference is using algo-rithms from automated deduction dedicated to first-order logic, such as theorem proving and model building. Theorem proving can help in finding contradictions or checking for new infor-mation. Finite model building can be seen as a complementary inference task to theorem proving, and it often makes sense to use both procedures in parallel. The models produced by model generators for texts not only show that the text is contradiction-free; they also can be used for disambiguation tasks and linking interpretation with the real world. To make interesting inferences, often additional background knowledge is required (not expressed in the analysed text or speech parts). This can be derived (and turned into first-order logic) from raw text, semi-structured databases or large-scale lexical databases such as WordNet. Promising future research directions of computational semantics are investigating alternative representation and inference methods (using weaker variants of first-order logic, reasoning with defaults), and developing evalu-ation methods measuring the semantic adequacy of systems and formalisms.},
author = {Bos, Johan},
doi = {10.1111/j.1749-818X.2011.00284.x},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/asp-stuff/Bos-2011-Language{\_}and{\_}Linguistics{\_}Compass.pdf:pdf},
issn = {1749818X},
journal = {Linguistics and Language Compass},
mendeley-groups = {ASP-stuff en computational semantics},
number = {6},
pages = {336--366},
title = {{A Survey of Computational Semantics: Representation, Inference and Knowledge in Wide-Coverage Text Understanding}},
volume = {5},
year = {2011}
}

@article{Baral2012,
abstract = {In order to answer questions and solve problems that require deeper reasoning with respect to a given text, it is necessary to automatically translate English sentences to formulas in an appropriate knowledge representation language. This paper focuses on a method to translate sentences to First-Order Logic (FOL). Our approach is inspired by Montague's use of lambda calculus formulas to represent the meanings of words and phrases. Since our target language is FOL, the meanings of words and phrases are represented as FOL-lambda formulas. In this paper we present algorithms that allow one to construct FOL-lambda formulas in an inverse manner. Given a sentence and its meaning and knowing the meaning of several words in the sentence our algorithm can be used to obtain the meaning of the other words in that sentence. In particular the two algorithms take as input two FOL-lambda formulas G and H and compute a FOL-lambda formula F such that F with input G, denoted by F@G, is H; respectively, G@F = H. We then illustrate our algorithm and present soundness, completeness and complexity results, and briefly mention the use of our algorithm in a NL Semantics system that translates sentences from English to formulas in formal languages. ? 2012 Springer-Verlag Berlin Heidelberg.},
author = {Baral, Chitta and Gonzalez, Marcos Alvarez and Gottesman, Aaron},
doi = {10.1007/978-3-642-30743-0_4},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/asp-stuff/fol2012.pdf:pdf},
isbn = {9783642307423},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
mendeley-groups = {ASP-stuff en computational semantics},
pages = {40--56},
title = {{The inverse lambda calculus algorithm for typed first order logic lambda calculus and its application to translating english to FOL}},
volume = {7265},
year = {2012}
}

@article{Bos1996,
author = {Bos, Johan},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/asp-stuff/10.1.1.43.9512.pdf:pdf},
mendeley-groups = {ASP-stuff en computational semantics},
title = {{Predicate Logic Unplugged Johan Bos}},
year = {1996}
}
@article{Blackburn2004,
author = {Blackburn, Patrick and Kohlhase, Michael},
doi = {10.1023/B:JLLI.0000024788.38738.bb},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/asp-stuff/10.1.1.23.6375.pdf:pdf},
issn = {09258531},
journal = {Journal of Logic, Language, and Information},
keywords = {computational semantics,discourse representation theory,model building,presupposition projection,theorem proving},
mendeley-groups = {ASP-stuff en computational semantics},
number = {2},
pages = {117--120},
title = {{Inference and Computational Semantics}},
volume = {13},
year = {2004}
}
@misc{Blackburn2005,
abstract = {1 Discourse Representation Theory 1.1 Au Overview of 1)1(1' . 1.2 Interpreting DRS . 1.3 DRT and First-Order Logic . 1.1 t)ll1 in Prohg 2 Building Discourse Representations 2.1 DRS-Threwling 2.2 Building DRSs with Lamlxla 2.3 Underspecified DRS 2.4 Merng into Darkness 3 Pronoun Re1ution 3.1 The Nature of Pronouns 3.2 1 mplement i ng Pronoun Resolution in DRT 3.3 Adding Hft1(XIVe Ik(JI1oI1E)s . . 3.4 The Focusing Algorithm},
archivePrefix = {arXiv},
arxivId = {arXiv:gr-qc/9809069v1},
author = {Blackburn, Patrick and Bos, Johan},
booktitle = {A first course in computational semantics. CSLI},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {9809069v1},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/asp-stuff/Blackburn-1997-RIN.pdf:pdf},
isbn = {1575864967 (Paperback) 1575864959 (Cloth)},
issn = {0717-6163},
mendeley-groups = {ASP-stuff en computational semantics},
pmid = {15003161},
primaryClass = {arXiv:gr-qc},
title = {{Representation and inference for natural language}},
url = {http://www.coli.uni-saarland.de/publikationen/softcopies/Blackburn:1997:RIN.pdf},
year = {2005}
}
@article{Baral2008,
abstract = {One way to solve the knowledge acquisition bottle- neck is to have ways to translate natural language sen- tences and discourses to a formal knowledge represen- tation language, especially ones that are appropriate to express domain knowledge in sciences, such as Biol- ogy. While there have been several proposals, includ- ing by Montague (1970), to give model theoretic se- mantics for natural language and to translate natural language sentences and discourses to classical logic, none of these approaches use knowledge representation languages that can express domain knowledge involv- ing normative statements and exceptions. In this pa- per we take a first step to illustrate how one can au- tomatically translate natural language sentences about normative statements and exceptions to representations in the knowledge representation language Answer Set Programming (ASP). To do this, we use $\lambda$-calculus rep- resentation of words and their composition as dictated by a CCG grammar.},
author = {Baral, Chitta and Dzifcak, Juraj and Son, Tran Cao},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/asp-stuff/AAAI08-130 (1).pdf:pdf},
isbn = {978-1-57735-368-3},
journal = {Proceedings of the 23rd AAAI Conference on Artificial Intelligence (AAAI-08)},
mendeley-groups = {ASP-stuff en computational semantics},
pages = {818--823},
title = {{Using Answer Set Programming and Lambda Calculus to Characterize Natural Language Sentences with Normatives and Exceptions}},
year = {2008}
}
@inproceedings{Costantini2010,
  title={Towards Translating Natural Language Sentences into ASP.},
  author={Costantini, Stefania and Paolucci, Alessio},
  booktitle={CILC},
  year={2010}
}
@article{Costantini2011,
author = {Costantini, Stefania and Florio, Niva and Paolucci, Alessio},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/asp-stuff/costantini2.pdf:pdf},
isbn = {9789898425799},
issn = {16130073},
journal = {CEUR Workshop Proceedings},
mendeley-groups = {ASP-stuff en computational semantics},
pages = {297--310},
title = {{A framework for structured knowledge extraction and representation from natural language via deep sentence analysis}},
volume = {810},
year = {2011}
}
@article{Baral2012a,
abstract = {We present a system capable of automatically solving com- binatorial logic puzzles given in (simplified) English. It uses an ontology to represent the puzzles in ASP which is appli- cable to a large set of logic puzzles. To translate the En- glish descriptions of the puzzles into this ontology, we use a $\lambda$-calculus based approach using Probabilistic Combinatorial Categorial Grammars (PCCG) where the meanings of words are associated with parameters to be able to distinguish be- tween multiple meanings of the same word.},
archivePrefix = {arXiv},
arxivId = {arXiv:1108.3850v1},
author = {Baral, Chitta and Dzifcak, Juraj},
eprint = {arXiv:1108.3850v1},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/asp-stuff/1108.3850v1.pdf:pdf},
isbn = {9781577355601},
journal = {Knowledge Representation and Reasoning (KR)},
keywords = {Short Papers},
mendeley-groups = {ASP-stuff en computational semantics},
pages = {573--577},
title = {{Solving Puzzles Described in English by Automated Translation to Answer Set Programming and Learning How to Do that Translation}},
year = {2012}
}

%--------------------

@article{Pereira1980,
author = {Pereira, F and Warren, D},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/1-s2.0-000437028090003X-main.pdf:pdf},
journal = {Artificial Intelligence},
number = {2},
pages = {231--278},
title = {{Definite Clause Grammar for Language Analysis - a survey of the formalism and a comparison with ATN}},
volume = {13},
year = {1980}
}

@inproceedings{Kiziltan2016,
author = {Kiziltan, Zeynep and Lippi, Marco and Torroni, Paolo},
booktitle = {Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI 2016)},
file = {:home/jens/Documents/2e{\_}master/thesis/papers/IJCAI-16{\_}paper{\_}250 (1).pdf:pdf},
keywords = {Constraints and Satisfiability},
number = {Ml},
pages = {744--750},
title = {{Constraint Detection in Natural Language Problem Descriptions}},
year = {2016}
}
@inproceedings{Pesic2007,
abstract = {Traditional workflow management systems (WFMSs) are not flexible enough to support loosely-structured processes. Furthermore, flexibility in contemporary WFMSs usually comes at a certain cost, such as lack of support for users, lack of methods for model analysis, lack of methods for analysis of past executions, etc. DECLARE is a proto-type of a WFMS that uses a constraint-based process modeling language for the development of declarative models describing loosely-structured processes. In this paper we show how DECLARE can support loosely-structured processes without sacrificing important WFMSs features like user support, model verification, analysis of past executions, changing models at run-time, etc.},
author = {Pesic, Maja and Schonenberg, Helen and {Van Der Aalst}, Wil M P},
booktitle = {Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOC},
doi = {10.1109/EDOC.2007.4384001},
file = {:home/jens/Documents/2e{\_}master/thesis/papers/04384001.pdf:pdf},
isbn = {0769528910},
issn = {15417719},
pages = {287--298},
title = {{DECLARE: Full support for loosely-structured processes}},
year = {2007}
}
@article{Jastram2010,
author = {Jastram, Michael},
file = {:home/jens/Documents/2e{\_}master/thesis/papers/seisconf.pdf:pdf},
title = {{ProR , an Open Source Platform for Requirements Engineering based on RIF}},
year = {2010}
}
@article{Schwitter2008,
abstract = {This paper introduces the controlled natural language PENG Light together with a language processor that is based on a bidirectional grammar. The language processor has the following interesting properties: (a) it translates declarative sentences written in PENG Light into a first-order logic notation (TPTP); (b) it generates declarative sentences in PENG Light taking syntactically annotated TPTP formulas as input; and (c) it translates questions written in PENG Light into (conjunctive) queries in TPTP notation and uses the TPTP representation of the query as a starting point for generating answers in PENG Light. Moreover, the controlled natural language processor can be interfaced directly with an automated reasoner in order to resolve anaphoric references and to answer questions stated in PENG Light.},
author = {Schwitter, Rolf},
doi = {10.1007/978-3-540-89378-3_17},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwitter - 2008 - Working for two A bidirectional grammar for a controlled natural language.pdf:pdf},
isbn = {3540893776},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Controlled natural languages,Grammar engineering,Human-computer interfaces,Knowledge representation,Question answering},
pages = {168--179},
title = {{Working for two: A bidirectional grammar for a controlled natural language}},
volume = {5360 LNAI},
year = {2008}
}
@article{Konrad2005,
abstract = {Embedded systems are pervasive and frequently used for critical systems with time-dependent functionality. Dwyer et al. (1999) have developed qualitative specification patterns to facilitate the specification of critical properties, such as those that must be satisfied by embedded systems. Thus far, no analogous repository has been compiled for realtime specification patterns. This paper makes two main contributions: First, based on an analysis of timing-based requirements of several industrial embedded system applications, we created real-time specification patterns in terms of three commonly used real-time temporal logics. Second, as a means to further facilitate the understanding of the meaning of a specification, we offer a structured English grammar that includes support for real-time properties. We illustrate the use of the real-time specification patterns in the context of property specifications of a real-world automotive embedded system.},
author = {Konrad, S. and Cheng, B.H.C.},
doi = {10.1109/ICSE.2005.1553580},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Konrad, Cheng - Unknown - Real-time Specification Patterns ∗ Categories and Subject Descriptors.pdf:pdf},
isbn = {1-59593-963-2},
journal = {Proceedings. 27th International Conference on Software Engineering, 2005. ICSE 2005.},
keywords = {Automotive engineering,Computer science,Embedded software,Embedded system,Formal specifications,Laboratories,Logic,Permission,Real time systems,Software engineering,embedded systems,formal specification,pervasive system,real-time specification patterns,real-time temporal logics,structured English grammar,temporal logic},
number = {October},
pages = {372--381},
title = {{Real-time specification patterns}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1553580},
year = {2005}
}
@article{Schwitter2003,
author = {Schwitter, Rolf and Ljungberg, Anna and Hood, David},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwitter, Ljungberg, Hood - 2003 - ECOLE–A Look-ahead Editor for a Controlled Language.pdf:pdf},
journal = {Eamt-Claw03},
pages = {141--150},
title = {{ECOLE–A Look-ahead Editor for a Controlled Language}},
year = {2003}
}
@article{Bruynooghe2014,
abstract = {This paper provides a gentle introduction to problem-solving with the IDP3 system. The core of IDP3 is a finite model generator that supports first-order logic enriched with types, inductive definitions, aggregates and partial functions. It offers its users a modeling language that is a slight extension of predicate logic and allows them to solve a wide range of search problems. Apart from a small introductory example, applications are selected from problems that arose within machine learning and data mining research. These research areas have recently shown a strong interest in declarative modeling and constraint-solving as opposed to algorithmic approaches. The paper illustrates that the IDP3 system can be a valuable tool for researchers with such an interest. The first problem is in the domain of stemmatology, a domain of philology concerned with the relationship between surviving variant versions of text. The second problem is about a somewhat related problem within biology where phylogenetic trees are used to represent the evolution of species. The third and final problem concerns the classical problem of learning a minimal automaton consistent with a given set of strings. For this last problem, we show that the performance of our solution comes very close to that of the state-of-the art solution. For each of these applications, we analyze the problem, illustrate the development of a logic-based model and explore how alternatives can affect the performance.},
author = {Bruynooghe, Maurice and Blockeel, Hendrik and Bogaerts, Bart and {De Cat}, Broes and {De Pooter}, Stef and Jansen, Joachim and Labarre, Anthony and Ramon, Jan and Denecker, Marc and Verwer, Sicco},
doi = {10.1017/S147106841400009X},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bruynooghe et al. - 2014 - Predicate logic as a modeling language modeling and solving some machine learning and data mining problems wi.pdf:pdf},
issn = {1471-0684},
journal = {Theory and Practice of Logic Programming},
keywords = {FO(⋅),IDP system,declarative modeling,deterministic finite state automaton,knowledge base systems,knowledge representation and reasoning,logic programming,phylogenetic tree,stemmatology},
number = {May 2014},
pages = {1--35},
title = {{Predicate logic as a modeling language: modeling and solving some machine learning and data mining problems with IDP3}},
url = {http://www.journals.cambridge.org/abstract{\_}S147106841400009X},
volume = {15},
year = {2014}
}
@article{Michael2001,
author = {Michael, J.B. and Ong, V.L. and Rowe, N.C.},
doi = {10.1109/TOOLS.2001.941679},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Michael, Ong, Rowe - 2001 - Natural-language processing support for developing policy-governed software systems.pdf:pdf},
isbn = {0-7695-1251-8},
journal = {Proceedings 39th International Conference and Exhibition on Technology of Object-Oriented Languages and Systems. TOOLS 39},
number = {July},
pages = {263--274},
title = {{Natural-language processing support for developing policy-governed software systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=941679},
year = {2001}
}
@article{DalCin2000,
abstract = {Requirements for dependable systems need to be understandable and, at the same time, have to satisfy consistency and non-ambiguity properties. We provide a means to specify nonfunctional requirements in terms of structured English sentences. We define their syntax by a clear and consistent notation. For verification, these sentences have to be transformed into a notation that can be interpreted by analysis tools. It is shown how this can be achieved via several translation steps},
author = {{Dal Cin}, M.},
doi = {10.1109/HASE.2000.895466},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dal Cin - 2000 - Structured language for specifications of quantitative requirements.pdf:pdf},
isbn = {0769509274},
issn = {15302059},
journal = {Proceedings of IEEE International Symposium on High Assurance Systems Engineering},
keywords = {Clocks,Information analysis,Logic,Natural languages,Performance analysis,Risk analysis,Specification languages,Stochastic processes,Stochastic systems,System performance},
pages = {221--227},
title = {{Structured language for specifications of quantitative requirements}},
volume = {2000-Janua},
year = {2000}
}
@article{Jak2008,
author = {Jak, Mirjana},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jakˇ - 2008 - Temporal Patterns for Document Verification.pdf:pdf},
number = {November},
title = {{Temporal Patterns for Document Verification}},
year = {2008}
}
@inproceedings{Konrad,
author = {Konrad, Sascha and Cheng, Betty H C},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Konrad, Cheng - Unknown - Real-time Specification Patterns ∗ Categories and Subject Descriptors.pdf:pdf},
isbn = {1581139632},
keywords = {formal specification,patterns,real-time requirements},
pages = {372--381},
title = {{Real-time Specification Patterns ∗ Categories and Subject Descriptors}}
}
@article{Nelken,
author = {Nelken, Rani and Francez, Nissim},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nelken, Francez - Unknown - Automatic Translation of Natural Language System Speci cations into Temporal Logic.pdf:pdf},
title = {{Automatic Translation of Natural Language System Speci cations into Temporal Logic}}
}
@article{Astrahan1975,
abstract = {SEQUEL is a nonprocedural language which does not make$\backslash$nuse of quantifiers or other mathematical concepts;$\backslash$nrather, SEQUEL uses a block structured format of$\backslash$nEnglish key words (hence the acronym ``Structured$\backslash$nEnglish Query Language'' ). SEQUEL is intended for$\backslash$ninteractive, problem solving use by people who have$\backslash$nneed for interaction with a large database but who are$\backslash$nnot trained programmers. This class of users includes$\backslash$nurban planners, sociologists, accountants, and other$\backslash$nprofessionals. The objective of the language is to$\backslash$nprovide a simple, easy-to-learn means of expressing the$\backslash$nprimitive actions used by people to obtain information$\backslash$nfrom tables, such as ``look up a value in a column.''$\backslash$nSEQUEL and its companion language, SQUARE, have been$\backslash$nshown to be relationally complete, i.e. equivalent in$\backslash$npower to Codd's relational calculus.},
author = {Astrahan, M. M. and Chamberlin, D. D.},
doi = {10.1145/361020.361215},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Astrahan, Chamberlin - 1975 - Implementation of a structured English query language.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {22,3,33,34,4,74,75,and phrases,cr categories,data,data organization,database,language,nonprocedural language,query,relational model,structure},
number = {10},
pages = {580--588},
title = {{Implementation of a structured English query language}},
volume = {18},
year = {1975}
}
@inproceedings{Kuhn2008,
  title={Writing support for controlled natural languages},
  author={Kuhn, Tobias and Schwitter, Rolf},
  booktitle={Proceedings of ALTA},
  pages={46--54},
  year={2008},
  organization={Citeseer}
}
@article{Flake2002,
abstract = {Model checking has received wide acceptance as a valuable technique in the eld of electronic design automation and is currently of growing interest in general systems design. Though its concepts and applications are well understood it often turns out that engineers have severe problems with the specication process and the underlying notation, i.e., formulation and understanding of specications through means of temporal logic formulae. In this article, we present an approach for a natural language{\{}oriented representation of temporal logic formulae by introducing patterns of structured English sentences for Clocked CTL (CCTL) specication. After outlining the basic patterns of the sentences we give their semantics by a translation to CCTL. A final example demonstrates their application. }},
author = {Flake, Stephan and M{\"{u}}ller, Wolfgang and Ruf, J{\"{u}}rgen},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Flake, M{\"{u}}ller, Ruf - 2002 - Structured English for Model Checking Specification.pdf:pdf},
journal = {Methoden und Beschreibungssprachen zur Modellierung und Verifikation von Schaltungen und Systemen},
number = {February},
pages = {99--108},
title = {{Structured English for Model Checking Specification}},
year = {2002}
}
@article{Ross2013,
annote = {Tabulation in RuleSpeak},
author = {Ross, Ronald G.},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ross - 2013 - Tabulation Lists in RuleSpeak A Primer.pdf:pdf},
title = {{Tabulation Lists in RuleSpeak: A Primer}},
year = {2013}
}
@article{Ross2009,
abstract = {What RuleSpeak is RuleSpeak is a set of practical guidelines for {\ldots} Expressing Business Rules in clear, unambiguous, well-structured English. Improving communication about Business Rules among business people, business analysts, and IT professionals. Bridging the gap between the language of business policies and legal obligations, and IT specifications oriented to system design and implementation. Avoiding common pitfalls associated with expressing guidance. Retaining product/service know-how in a manageable, reusable form. In the words of an experienced practitioner {\ldots}},
annote = {GUIDELINES, niet formeel!},
author = {Ross, Ronald G},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ross - 2009 - Basic RuleSpeak Guidelines.pdf:pdf},
pages = {23},
title = {{Basic RuleSpeak Guidelines}},
url = {http://www.brsolutions.com},
year = {2009}
}
@article{Kuhn2010,
abstract = {This paper presents a general framework called ontographs that relies on a graphical notation and enables the tool-independent and reliable evaluation of human understandability of knowledge represen- tation languages. An experiment with 64 participants is presented that applies this framework and compares a controlled natural language to a common formal language. The results show that the controlled natural language is easier to understand, needs less learning time, and is more accepted by its users.},
author = {Kuhn, Tobias},
doi = {10.1007/978-3-642-14418-9_1},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhn - 2010 - An Evaluation Framework for Controlled Natural Languages.pdf:pdf},
isbn = {978-3-642-14418-9},
journal = {Controlled Natural Language},
pages = {1--20},
title = {{An evaluation framework for controlled natural languages}},
url = {http://www.springerlink.com/index/LL26N53P624QWN41.pdf http://link.springer.com/10.1007/978-3-642-14418-9{\_}1},
year = {2010}
}
@article{Ross2013a,
author = {Ross, Ronald G.},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ross - 2013 - Decision Tables A Primer - How to Use TableSpeak.pdf:pdf},
keywords = {business rules,decision,decision table},
title = {{Decision Tables: A Primer - How to Use TableSpeak}},
year = {2013}
}
@article{Ostermayer2012,
author = {Ostermayer, Ludwig and Seipel, Dietmar},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ostermayer, Seipel - 2012 - Knowledge engineering for business rules in prolog.pdf:pdf},
journal = {Proceedings of the 26th Workshop on Logic Programming},
keywords = {business,business rules,knowledge engineering,logic programming},
pages = {24--25},
title = {{Knowledge engineering for business rules in prolog}},
url = {http://www1.pub.informatik.uni-wuerzburg.de/databases/papers/wlp{\_}2012{\_}8.pdf},
year = {2012}
}
@article{Spreeuwenberg2010,
author = {Spreeuwenberg, Silvie and Healy, Keri Anderson},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spreeuwenberg, Healy - 2010 - SBVR ' s Approach to Controlled Natural Language.pdf:pdf},
journal = {Controlled Natural Language},
keywords = {business rules,business vocabulary,semantic,semantics},
pages = {155--169},
title = {{SBVR ' s Approach to Controlled Natural Language}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-14418-9{\_}10},
year = {2010}
}
@article{Kuhn2014,
abstract = {What is here called controlled natural language (CNL) has traditionally been given many different names. Especially during the last four decades, a wide variety of such languages have been designed. They are applied to improve communication among humans, to improve translation, or to provide natural and intuitive representations for formal notations. Despite the apparent differences, it seems sensible to put all these languages under the same umbrella. To bring order to the variety of languages, a general classification scheme is presented here. A comprehensive survey of existing English-based CNLs is given, listing and describing 100 languages from 1930 until today. Classification of these languages reveals that they form a single scattered cloud filling the conceptual space between natural languages such as English on the one end and formal languages such as propositional logic on the other. The goal of this article is to provide a common terminology and a common model for CNL, to contribute to the unde...},
archivePrefix = {arXiv},
arxivId = {arXiv:1507.01701v1},
author = {Kuhn, Tobias},
doi = {10.1162/COLI_a_00168},
eprint = {arXiv:1507.01701v1},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhn - 2014 - A Survey and Classification of Controlled Natural Languages.pdf:pdf},
isbn = {9781608459858},
issn = {0891-2017},
journal = {Computational Linguistics},
month = {mar},
number = {1},
pages = {121--170},
title = {{A Survey and Classification of Controlled Natural Languages}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/COLI{\_}a{\_}00168},
volume = {40},
year = {2014}
}
@inproceedings{Davis2010,
author = {Davis, Brian and Dantuluri, Pradeep and Dragan, Laura and Handschuh, Siegfried and Cunningham, Hamish},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-14418-9_12},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davis et al. - 2010 - On Designing Controlled Natural Languages for Semantic Annotation.pdf:pdf},
isbn = {3642144179},
issn = {03029743},
pages = {187--205},
title = {{On designing controlled natural languages for semantic annotation}},
url = {http://link.springer.com/10.1007/978-3-642-14418-9{\_}12},
volume = {5972 LNAI},
year = {2010}
}
@article{Kuhn2013,
abstract = {Controlled natural languages (CNL) with a direct mapping to formal logic have been proposed to improve the usability of knowledge representation systems, query interfaces, and formal specifications. Predictive editors are a popular approach to solve the problem that CNLs are easy to read but hard to write. Such predictive editors need to be able to "look ahead" in order to show all possible continuations of a given unfinished sentence. Such lookahead features, however, are difficult to implement in a satisfying way with existing grammar frameworks, especially if the CNL supports complex nonlocal structures such as anaphoric references. Here, methods and algorithms are presented for a new grammar notation called Codeco, which is specifically designed for controlled natural languages and predictive editors. A parsing approach for Codeco based on an extended chart parsing algorithm is presented. A large subset of Attempto Controlled English (ACE) has been represented in Codeco. Evaluation of this grammar and the parser implementation shows that the approach is practical, adequate and efficient.},
archivePrefix = {arXiv},
arxivId = {1211.3643},
author = {Kuhn, Tobias},
doi = {10.1007/s10849-012-9167-z},
eprint = {1211.3643},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuhn - Unknown - A Principled Approach to Grammars for Controlled Natural Languages and Predictive Editors.pdf:pdf},
issn = {09258531},
journal = {Journal of Logic, Language and Information},
keywords = {Anaphoric references,Attempto Controlled English,Chart parsing,Controlled natural languages,Predictive editors},
number = {1},
pages = {33--70},
title = {{A Principled Approach to Grammars for Controlled Natural Languages and Predictive Editors}},
volume = {22},
year = {2013}
}
@article{Ross2009a,
abstract = {A practical implementation of the SBVR method of desiging bus. terms and rules},
annote = {Welke zinsstructuren toegelaten zijn},
author = {Ross, Ronald G},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ross - 2009 - RuleSpeak Sentence Forms.pdf:pdf},
journal = {RuleSpeak},
pages = {10},
title = {{RuleSpeak Sentence Forms}},
year = {2009}
}
@inproceedings{Wyner2010,
abstract = {This collaborative report highlights the properties and prospects of Controlled Natural Languages (CNLs). The report poses a range of questions concerning the goals of the CNL, the design, the linguistic aspects, the relationships and evaluation of CNLs, and the application tools. In posing the questions, the report attempts to structure the field of CNLs and to encourage further systematic discussion by researchers and developers.},
author = {Wyner, Adam and Angelov, Krasimir and Barzdins, Guntis and Damljanovic, Danica and Davis, Brian and Fuchs, Norbert and Hoefler, Stefan and Jones, Ken and Kaljurand, Kaarel and Kuhn, Tobias and Luts, Martin and Pool, Jonathan and Rosner, Mike and Schwitter, Rolf and Sowa, John},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-14418-9_17},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wyner et al. - 2010 - On Controlled Natural Languages Properties and Prospects.pdf:pdf},
isbn = {3642144179},
issn = {03029743},
pages = {281--289},
title = {{On controlled natural languages: Properties and prospects}},
volume = {5972 LNAI},
year = {2010}
}
@article{Clark2005,
annote = {CPL: nogal oud},
author = {Clark, Peter and Harrison, Philip and Jenkins, Thomas and Thompson, John A and Wojcik, Richard H},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Clark et al. - 2005 - Acquiring and Using World Knowledge Using a Restricted Subset of English.pdf:pdf},
isbn = {1577352343},
journal = {FLAIRS Conference},
pages = {506--511},
title = {{Acquiring and Using World Knowledge Using a Restricted Subset of English.}},
year = {2005}
}
@article{Dellis2010,
annote = {Thesis rond combineren Attempto Controlled English met KBs om queries te beantwoorden (en bewijzen)},
author = {Dellis, NC},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dellis - 2010 - Using Controlled Natural Language for World Knowledge Reasoning.pdf:pdf},
keywords = {Answer Engine,Automated Reasoning,Query System},
title = {{Using Controlled Natural Language for World Knowledge Reasoning}},
url = {http://scholarlyrepository.miami.edu/oa{\_}theses/48/},
year = {2010}
}
@article{OMG2008,
annote = {SBVR specificatie},
author = {OMG},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/OMG - 2008 - Semantics of Business Vocabulary and Business Rules (SBVR), v1.0. OMG Available Specification. httpwww.omg.orgdocsformal08-.pdf:pdf},
number = {May},
pages = {392},
title = {{Semantics of Business Vocabulary and Business Rules (SBVR), v1.0. OMG Available Specification. http://www.omg.org/docs/formal/08-01-02.pdf}},
url = {http://www.omg.org/spec/QVT/1.0/PDF},
year = {2008}
}
@article{Schwitter2005,
author = {Schwitter, Rolf},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwitter - 2005 - Controlled natural language as interface language to the semantic web.pdf:pdf},
journal = {2nd Indian International Conference on Artificial},
pages = {1699--1718},
title = {{Controlled natural language as interface language to the semantic web}},
url = {http://web.science.mq.edu.au/{~}rolfs/papers/IICAI-schwitter-2005.pdf},
year = {2005}
}
@article{Schwitter2006,
  title={Let's talk in description logic via controlled natural language},
  author={Schwitter, Rolf and Tilbrook, Marc and others},
  year={2006},
  publisher={Tokyo: Japanese Society for Artificial Intelligence}
}
@article{White2009,
annote = {Firefox extensie, woord voorspelling},
author = {White, Colin and Schwitter, Rolf},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/White, Schwitter - 2009 - An Update on PENG Light.pdf:pdf},
journal = {Proceedings of the Australasian Language Technology Association Workshop},
pages = {80--88},
title = {{An Update on PENG Light}},
year = {2009}
}
@article{Wahlster,
abstract = {Natural language processing is a prerequisite for advanced knowledge-based systems since the ability to acquire, retrieve, exploit and present knowledge critically depends on natural language comprehension and production. Natural language concepts guide the interpretation of what we see, hear, read, or experience with other senses. In the first part of the paper, we illustrate the needed capabilities of cooperative dialog systems with a detailed example: the interaction between a customer and a clerk at an information desk in a train station. It is shown, that natural language systems cannot just rely on knowledge about syntactical and semantical aspects of language but also have to exploit conceptual and inferential knowledge, and a user model. In the remainder, we analyze and evaluate three natural language systems which were introduced to the commercial market in 1985: Language Craft™ by Carnegie Group Inc., NLMenu by Texas Instruments Inc., and Q {\&} A™ by Symantec Inc. The detailed examination of these systems shows their capabilities and limitations. We conclude that the technology for limited natural language access systems is available now, but that in the forseeable future the capabilities of such systems in no way match human performance in face-to-face communication.},
author = {Wahlster, Wolfgang},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wahlster - Unknown - The Role of Natural Language in Advanced Knowledge-Based Systems.pdf:pdf},
pages = {1--19},
title = {{The Role of Natural Language in Advanced Knowledge-Based Systems}}
}
@article{Bajwa2012,
abstract = {Object Constraint Language (OCL) is the only available language to annotate the Unified Modeling Language (UML) based conceptual schema (CS) of a software application. In practice, the constraints are captured in a natural language (NL) such as English and then an OCL expert manually transforms the NL expressions to OCL syntax. However, it is a common knowledge that OCL is difficult to write specifically for the novel users with little or no prior knowledge of OCL. In recent times, model transformation technology has made transformation of one language to another simpler and easier. In this paper we present a novel approach to automatically transform NL specification of software constraints to OCL constraints. In NL to OCL transformation, Semantics of Business Vocabulary and Rules (SBVR) standard is used as an intermediate representation due to a couple of reasons: first of all, SBVR is based on higher order logic that simplifies the transformation of SBVR to other formal languages such as OCL. Moreover, SBVR used syntax of natural language and thus is close to human beings. The presented NL to OCL transformation via SBVR will not only simplify the process of generating OCL constraints but also generate accurate models in less time.},
author = {Bajwa, Imran Sarwar and Lee, Mark and Bordbar, Behzad},
doi = {10.1016/j.jksuci.2011.12.003},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bajwa, Lee, Bordbar - 2012 - Translating natural language constraints to OCL.pdf:pdf},
isbn = {1319-1578},
issn = {13191578},
journal = {Journal of King Saud University - Computer and Information Sciences},
keywords = {english constraints,natural language processing},
number = {2},
pages = {117--128},
title = {{Translating natural language constraints to OCL}},
url = {http://dx.doi.org/10.1016/j.jksuci.2011.12.003},
volume = {24},
year = {2012}
}
@article{Pease2010,
annote = {Controlled English to Logic Translation using ontology},
author = {Pease, Adam and Li, John},
doi = {10.1007/978-90-481-8847-5_11},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pease, Li - 2010 - Controlled english to logic translation.pdf:pdf},
isbn = {9789048188468},
journal = {Theory and Applications of Ontology: Computer Applications},
pages = {245--258},
title = {{Controlled english to logic translation}},
year = {2010}
}
@article{Schwitter2004,
author = {Schwitter, R and Tilbrook, M},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwitter, Tilbrook - 2004 - Controlled Natural Language meets the Semantic Web.pdf:pdf},
journal = {Proceedings of the Australasian Language Technology Workshop},
pages = {55--62},
title = {{Controlled Natural Language meets the Semantic Web}},
year = {2004}
}
@article{Fantechi1994,
author = {Fantechi, A. and Gnesi, S. and Ristori, G. and Carenini, M. and Vanocchi, M. and Moreschini, P.},
doi = {10.1007/BF01384048},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fantechi et al. - 1994 - Assisting requirement formalization by means of natural language translation.pdf:pdf},
issn = {09259856},
journal = {Formal Methods in System Design},
keywords = {action-based logics,natural language,requirement formalization},
number = {3},
pages = {243--263},
title = {{Assisting requirement formalization by means of natural language translation}},
volume = {4},
year = {1994}
}
@article{Fuchs2008,
abstract = {Abstract Attempto Controlled English (ACE) is a controlled natural language, ie a precisely defined subset of English that can automatically and unambiguously be translated into first- order logic. ACE may seem to be completely natural, but is actually a formal language, ...},
annote = {Multi-woorden moeten met streepje:
{\textgreater} A student is interested-in a course
vs.
{\textgreater} A student is interested in a classroom.

Paraphrase beschikbaar voor zeker te zijn juiste interpretatie

Course: http://attempto.ifi.uzh.ch/site/courses/files/bonn2008.pdf

Open problemen:

- rules do not always lead to natural interpretation
- sometimes result in stilted English
- Can we control all ambiguities with this strategy?
- Does strategy scale up to a larger fragment of ACE?},
author = {Fuchs, Norbert E. and Kaljurand, Kaarel and Kuhn, Tobias},
doi = {10.1007/978-3-540-85658-0_3},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fuchs, Kaljurand, Kuhn - 2008 - Attempto controlled english for knowledge representation.pdf:pdf},
isbn = {3540856560},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {104--124},
title = {{Attempto controlled english for knowledge representation}},
volume = {5224 LNCS},
year = {2008}
}
@article{Ambriola1997,
abstract = {The importance of requirements, which in practice often means natural language requirements, for a successful software project cannot be underestimated. Although requirement analysis has been traditionally reserved to the experience of professionals, there is no reason not to use various automatic techniques to the same end. In this paper we present Circe, a Web-based environment for aiding in natural language requirements gathering, elicitation, selection, and validation and the tools it integrates. These tools have been used in several experiments both in academic and in industrial environments. Among other features, Circe can extract abstractions from natural language texts, build various models of the system described by the requirements, check the validity of such models, and produce functional metric reports. The environment can be easily extended to enhance its natural language recognition power or to add new models and views on them},
annote = {Circo tool

Vooral werk in requirements engineering. Custom rules based on type of diagram (dataflow, ...)},
author = {Ambriola, V and Gervasi, Vincenzo},
doi = {10.1109/ASE.1997.632822},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ambriola, Gervasi - 1997 - Processing natural language requirements.pdf:pdf},
isbn = {0-8186-7961-1},
journal = {Proceedings 12th IEEE International Conference Automated Software Engineering},
keywords = {Circe,Decoding,Documentation,Failure analysis,Information analysis,Information resources,Natural language processing,Natural languages,Power engineering and energy,Power system modeling,Web-based environment,Writing,formal specification,formal verification,functional metric reports,natural language recognition,natural language requirements,natural language requirements processing,natural language texts,natural languages,programming environments,requirement analysis,selection,software project,systems analysis,validation},
pages = {36--45},
title = {{Processing natural language requirements}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=632822},
year = {1997}
}
@article{Levy2013,
annote = {Gewoon beschrijving van een manueel proces},
author = {L{\'{e}}vy, Fran{\c{c}}ois and Nazarenko, Adeline},
doi = {10.1007/978-3-642-39617-5-5},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\'{e}}vy, Nazarenko - 2013 - Formalization of natural language regulations through sbvr structured english (tutorial).pdf:pdf},
isbn = {9783642396168},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {19--33},
title = {{Formalization of natural language regulations through sbvr structured english (tutorial)}},
volume = {8035 LNCS},
year = {2013}
}
@article{Fuchs,
author = {Fuchs, N.E. and Schwertel, U. and Torge, S.},
doi = {10.1109/ASE.1999.802325},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fuchs, Schwertel, Torge - Unknown - Controlled natural language can replace first-order logic.pdf:pdf},
isbn = {0-7695-0415-9},
journal = {14th IEEE International Conference on Automated Software Engineering},
pages = {295--298},
title = {{Controlled natural language can replace first-order logic}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=802325}
}
@article{Neill2003,
abstract = {Little contemporary data exists for document actual practices of software professionals for software requirements elicitation, requirements specification, document development, and specification validation. This exploratory survey and its quantitative results offer opportunities for further interpretation and comparison.},
author = {Neill, C.J. and Laplante, P.a.},
doi = {10.1109/MS.2003.1241365},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neill, Laplante - 2003 - Requirements engineering The state of the practice.pdf:pdf},
issn = {0740-7459},
journal = {IEEE Software},
number = {6},
pages = {40--45},
pmid = {991663109468517369},
title = {{Requirements engineering: The state of the practice}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1241365},
volume = {20},
year = {2003}
}
@article{Gervasi2002,
abstract = {In this paper, we report on our experiences of using lightweight formal methods for the partial validation of natural language requirements documents. We describe our approach to checking properties of models obtained by shallow parsing of natural language requirements, and apply it to a case study based on part of a NASA specification of the Node Control Software on the International Space Station. The experience reported supports our position that it is feasible and useful to perform automated analysis of requirements expressed in natural language. Indeed, we identified a number of errors in our case study that were also independently discovered and corrected by NASA's Independent Validation and Verification Facility in a subsequent version of the same document, and others that were not discovered. The paper describes the techniques we used, the errors we found and reflects on the lessons earned.},
annote = {Gelijkaardig aan doel thesis},
author = {Gervasi, Vincenzo and Nuseibeh, Bashar},
doi = {10.1002/spe.430},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gervasi, Nuseibeh - 2002 - Lightweight validation of natural language requirements.pdf:pdf},
isbn = {VO  -},
issn = {00380644},
journal = {Software - Practice and Experience},
keywords = {Lightweight formal methods,Natural language requirements,Requirements validation},
number = {2},
pages = {113--133},
title = {{Lightweight validation of natural language requirements}},
volume = {32},
year = {2002}
}
@article{Ambriola1997a,
author = {Ambriola, V. and Gervasi, V.},
doi = {10.1109/SEE.1997.591824},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ambriola, Gervasi - 1997 - An environment for cooperative construction of natural-language requirement bases.pdf:pdf},
isbn = {0-8186-8019-9},
journal = {Proceedings 8th Conference on Software Engineering Environments},
pages = {124--130},
title = {{An environment for cooperative construction of natural-language requirement bases}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=591824},
year = {1997}
}
@article{Njonko2014,
abstract = {Business rules represent the primary means by which companies define their business, perform their actions in order to reach their objectives. Thus, they need to be expressed unambiguously to avoid inconsistencies between business stakeholders and formally in order to be machine-processed. A promising solution is the use of a controlled natural language (CNL) which is a good mediator between natural and formal languages. This paper presents RuleCNL, which is a CNL for defining business rules. Its core feature is the alignment of the business rule definition with the business vocabulary which ensures traceability and consistency with the business domain. The RuleCNL tool provides editors that assist end-users in the writing process and automatic mappings into the Semantics of Business Vocabulary and Business Rules (SBVR) standard. SBVR is grounded in first order logic and includes constructs called semantic formulations that structure the meaning of rules. {\textcopyright} 2014 Springer International Publishing Switzerland.},
annote = {Geen duidelijkheid over semantiek, nooit gecite!!!},
archivePrefix = {arXiv},
arxivId = {1406.2096},
author = {Njonko, Paul Brillant Feuto and Cardey, Sylviane and Greenfield, Peter and {El Abed}, Walid},
doi = {10.1007/978-3-319-10223-8_7},
eprint = {1406.2096},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Njonko et al. - 2014 - RuleCNL A controlled natural language for business rule specifications.pdf:pdf},
isbn = {9783319102221},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Automatic Mapping,Business Rule,Controlled Natural Language,Semantics of Business Vocabulary and Business Rule},
pages = {66--77},
title = {{RuleCNL: A controlled natural language for business rule specifications}},
volume = {8625 LNAI},
year = {2014}
}
@article{Gervasi2005,
abstract = {The use of logic in identifying and analyzing inconsistency in requirements from multiple stakeholders has been found to be effective in a number of studies. Nonmonotonic logic is a theoretically well-founded formalism that is especially suited for supporting the evolution of requirements. However, direct use of logic for expressing requirements and discussing them with stakeholders poses serious usability problems, since in most cases stakeholders cannot be expected to be fluent with formal logic. In this article, we explore the integration of natural language parsing techniques with default reasoning to overcome these difficulties. We also propose a method for automatically discovering inconsistencies in the requirements from multiple stakeholders, using both theorem-proving and model-checking techniques, and show how to deal with them in a formal manner. These techniques were implemented and tested in a prototype tool called CARL. The effectiveness of the techniques and of the tool are illustrated by a classic example involving conflicting requirements from multiple stakeholders.},
author = {Gervasi, Vincenzo and Zowghi, Didar},
doi = {10.1145/1072997.1072999},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gervasi, Zowghi - 2005 - Reasoning about inconsistencies in natural language requirements.pdf:pdf},
isbn = {1049-331X},
issn = {1049-331X},
journal = {ACM Trans. Softw. Eng. Methodol.},
number = {3},
pages = {277--330},
title = {{Reasoning about inconsistencies in natural language requirements}},
url = {http://doi.acm.org/10.1145/1072997.1072999{\%}5Cnhttp://dl.acm.org/ft{\_}gateway.cfm?id=1072999{\&}type=pdf},
volume = {14},
year = {2005}
}
@article{Luisa2004,
abstract = {Numerous studies in recent months have proposed the use of linguistic instruments to support requirements analysis. There are two main reasons for this: (i) the progress made in natural language processing, (ii) the need to provide the developers of software systems with support in the early phases of requirements definition and conceptual modelling. This paper presents the results of an online market research intended (a) to assess the economic advantages of developing a CASE tool that integrates linguistic analysis techniques for documents written in natural language, and (b) to verify the existence of potential demand for such a tool. The research included a study of the language ranging from completely natural to highly restricted used in documents available for requirements analysis, an important factor given that on a technological level there is a trade-off between the language used and the performance of the linguistic instruments. To determine the potential demand for such tool, some of the survey questions dealt with the adoption of development methodologies and consequently with models and support tools; other questions referred to activities deemed critical by the companies involved. Through statistical correspondence analysis of the responses, we were able to outline two "profiles" of companies that correspond to two potential market niches which are characterised by their very different approach to software development.},
author = {Luisa, Mich and Mariangela, Franch and Pierluigi, Novi Inverardi},
doi = {10.1007/s00766-003-0179-8},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luisa, Mariangela, Pierluigi - 2004 - Market Research for Requirements Analysis Using Linguistic Tools.pdf:pdf},
isbn = {0947-3602},
issn = {0947-3602},
journal = {Requirements Engineering},
keywords = {1 objectives and structure,conceptual modelling {\ae} market,nlp-based case tools {\ae},of the paper,potential demand {\ae},requirements analysis,research {\ae}},
number = {1},
pages = {40--56},
title = {{Market Research for Requirements Analysis Using Linguistic Tools}},
url = {http://dl.acm.org/citation.cfm?id=1008824},
volume = {9},
year = {2004}
}
@article{Berry2003,
abstract = {This handbook is about writing software requirements specifications and legal contracts, two kinds of docu- ments with similar needs for completeness, consistency, and precision. Particularly when these are written, as they usually are, in natural language, ambiguity—by any definition—is a major cause of their not specifying what they should. Simple misuse of the language in which the document is written is one source of these ambiguities. This handbook describes the ambiguity phenomenon from several points of view, including linguistics, software engineering, and the law. Several strategies for avoiding and detecting ambiguities are presented. Strong emphasis is given on the problems arising from the use of heavily used and seemingly unambiguous words and phrases such as “all”, “each”, and “every” in defining or referencing sets; positioning of “only”, “also”, and “even”; precedences of “and” and “or”; “a”, “all”, “any”, “each”, “one”, “some”, and “the” used as quantifiers; “or” and “and/or”; “that” vs. “which”; parallelism; pronouns referring to an idea; multiple adjectives; etc. Many examples from requirements documents and legal documents are examined. While no guide can overcome the careless or indifferent writer, this handbook is offered as a guide both for writing better requirements or contracts and for inspecting them for potential ambiguities. 1},
annote = {lijst van veel mogelijke ambigu{\"{i}}teiten in taal},
author = {Berry, Daniel M.; Erik Kamsties},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berry - 2003 - From Contract Drafting to Software Specification Linguistic Sources of Ambiguity.pdf:pdf},
journal = {Automated Software Engineering, 1997 {\ldots}},
pages = {1--80},
title = {{From Contract Drafting to Software Specification: Linguistic Sources of Ambiguity}},
url = {https://cs.uwaterloo.ca/{~}dberry/handbook/ambiguityHandbook.pdf{\%}5Cnhttp://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=632822{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.9.7928{\&}rep=rep1{\&}type=pdf},
year = {2003}
}
@article{Erbach1995,
abstract = {ProFIT is an extension of Standard Prolog with Features, Inheritance and Templates. ProFIT allows the programmer or grammar developer to declare an inheritance hierarchy, features and templates. Typed feature terms can be used in ProFIT programs together with Prolog terms to provide a clearer description language for linguistic structures. ProFIT compiles all typed feature terms into a Prolog term representation, so that the built-in Prolog term unification can be used for the unification of typed feature structures, and no special unification algorithm is needed. ProFIT programs are compiled into Prolog programs, so that no meta-interpreter is needed for their execution. ProFIT thus provides a direct step from grammars developed with typed feature terms to Prolog programs usable for applications.},
author = {Erbach, Gregor},
doi = {http://dx.doi.org/10.3115/976973.976999},
file = {:home/jens/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Erbach - 1995 - ProFit - Prolog with Features, Inheritance, and Templates.pdf:pdf},
journal = {Proceedings of the 7th Conference of the European Chapter of the Association for Computational Linguistics. EACL-95, March 27-31, University College Dublin, Ireland},
pages = {180--187},
title = {{ProFit - Prolog with Features, Inheritance, and Templates}},
year = {1995}
}

@article{Schwitter2002,
abstract = {As a Specification Rolf Schwitter Centre for Technology Macquarie University Sydney, NSW 2109 Australia schwittics.mq.edu.au},
author = {Schwitter, Rolf},
doi = {10.1109/DEXA.2002.1045903},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/10.1.1.88.1151.pdf:pdf},
isbn = {0-7695-1668-8},
issn = {1529-4188},
journal = {Interpreting},
pages = {228--232},
title = {{English as a Formal Specification Language}},
url = {http://web.science.mq.edu.au/{~}rolfs/papers/nlis2002.pdf},
year = {2002}
}
@article{Schwitter2004b,
abstract = {In this case study I argue for the usage of a machine-oriented controlled natural language as interface language to knowledge systems. Instead of using formal languages that are difficult to learn and to remember for non-specialists, authors should be able to write specifications texts in a well-defined subset of English that can be unambiguously processed by a computer. This subset of computer-processable English (PENG) consists of a restricted grammar and lexicon and is used together with an intelligent text editor that guides the writing process. The editor of the PENG system communicates with a language processor that generates logical structures while the author writes a specification text. The language processor is connected via a server with reasoning services that allow for acceptability checking and question answering. Texts written in PENG look seemingly informal and are easy to write and understand for humans but have first-order equivalent properties.},
author = {Schwitter, R},
file = {:home/jens/stack/Documents/2e{\_}master/thesis/papers/chp{\%}3A10.1007{\%}2F978-3-540-30132-5{\_}97.pdf:pdf},
journal = {Knowledge-Based Intelligent Information and Engineering Systems},
pages = {711--717},
title = {{Representing knowledge in controlled natural language: a case study}},
year = {2004}
}

@Article{Mukherjee2008,
author="Mukherjee, Anirban
and Garain, Utpal",
title="A review of methods for automatic understanding of natural language mathematical problems",
journal="Artificial Intelligence Review",
year="2008",
month="Apr",
day="01",
volume="29",
number="2",
pages="93--122",
abstract="This article addresses the problem of understanding mathematics described in natural language. Research in this area dates back to early 1960s. Several systems have so far been proposed to involve machines to solve mathematical problems of various domains like algebra, geometry, physics, mechanics, etc. This correspondence provides a state of the art technical review of these systems and approaches proposed by different research groups. A unified architecture that has been used in most of these approaches is identified and differences among the systems are highlighted. Significant achievements of each method are pointed out. Major strengths and weaknesses of the approaches are also discussed. Finally, present efforts and future trends in this research area are presented.",
issn="1573-7462",
doi="10.1007/s10462-009-9110-0",
url="https://doi.org/10.1007/s10462-009-9110-0"
}

@book{manning1999foundations,
  title={Foundations of statistical natural language processing},
  author={Manning, Christopher D and Manning, Christopher D and Sch{\"u}tze, Hinrich},
  year={1999},
  publisher={MIT press}
}

@inproceedings{sqalli1996inference,
  title={Inference-based constraint satisfaction supports explanation},
  author={Sqalli, Mohammed H and Freuder, Eugene C},
  booktitle={AAAI/IAAI, Vol. 1},
  pages={318--325},
  year={1996}
}

@mastersthesis{msc/Claes17,
  author    = {Jens Claes},
  title     = {Automatic Translation of Logic Grid Puzzles into a Typed Logic},
  school    = {KU Leuven},
  year      = {2017},
  address   = {Leuven, Belgium},
  month     = {June},
}

@article{DBLP:journals/coling/MarcusSM94,
  author    = {Mitchell P. Marcus and
               Beatrice Santorini and
               Mary Ann Marcinkiewicz},
  title     = {Building a Large Annotated Corpus of English: The Penn Treebank},
  journal   = {Computational Linguistics},
  volume    = {19},
  number    = {2},
  pages     = {313--330},
  year      = {1993},
  timestamp = {Tue, 06 Dec 2005 15:19:37 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/coling/MarcusSM94},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
