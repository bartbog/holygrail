Notes : 

We can specify the task of explainable agency more explicitly as: 

* Given a complex set of objectives that require an agent’s extended activity over time 
* Given background knowledge about categories, relations, and activities that are relevant to these objectives; 

* Produce records of decisions made during plan generation, execution, and monitoring in pursuit of these aims; 
* Produce summary reports, in human accessible terms, of the agent’s mental and physical activities; 
* Produce understandable answers to questions that are posed about specific choices and the reasons for them.

The agent must be able to explain decisions made during plan generation. This should include stating the al ternatives it considered, giving its reasons for selecting them over alternatives, and describing its expectations for each option. 
This can build on the foundations laid by recent work in explainable planning (e.g., Zhang, Zhuo, and Kambhampati 2015).  The explainable agent must be able to report which ac-tions it executed, presenting this information at different levels of abstraction as appropriate. 
The system should clarify how these actions relate to inferences it made, goals it adopted, and plans it generated. 

An autonomous agent must be able to explain how actual events diverged from a plan and how it adapted in response. It should also state on request the reasons for taking these steps, propose courses of action that seem better in hindsight, and even discuss what it would have done if other situations had arisen. • An explainable agent must be able to communicate its de- cisions and reasons in ways that make contact with hu- man concepts. This does not mean they must encode con- tent in the same internal formalism, but the agent should present information in terms of beliefs, goals, and ac- tivities that people find familiar. These are often orga- nized hierarchically, which should supp