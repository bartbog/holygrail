We explore the problem of step-wise explaining how to solve constraint satisfaction problems, with a use case on logic grid puzzle. More specifically, we look at the problem of explaining the inference steps that one can take during propagation, in a way that is easy to interpret for a person. We hence give the constraint solver explainable agency, which can help in building trust in the constraint solver by being able to understand and even learn from the explanation.
The main challenge is that of finding a sequence of simple explanations, where each explanation should aim to be as cognitively easy as possible so that a human can verify and understand them. This contrasts with the arbitrary combination of facts and constraints that the solver may use when propagating, which often depends on the ordering of the constraints.
We propose the use of a cost function to quantify how simple an individual explanation of an inference step is, and identify the explanation-production problem of finding the best sequence of explanations of a CSP. 
We propose an approach that is agnostic of the underlying constraint propagation mechanisms, and that can provide explanations even for inference steps resulting from combining of constraints.
Our proposed algorithm iteratively constructs the explanation sequence by using an optimistic estimate of the cost function of individual explanations to effectively search for the best explanation at each step.
Our experiments on logic grid puzzles show the feasibility of the approach in terms of the quality of the individual explanations and the resulting sequences obtained.