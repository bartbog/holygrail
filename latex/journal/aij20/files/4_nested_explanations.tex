When we implemented the ideas from the previous section and applied them to logic grid puzzles, as explained in Section \ref{sec:zebra}, we noticed that 
for the most \textit{difficult} puzzles, some explanation steps were still quite hard to understand.
An example is depicted in Figure \ref{fig:pasta_diff}.
It uses a complicated (disjunctive) clue (``The person who ordered Rotini is either the person who paid \$8 more than Damon or the person who paid \$8 less than Damon'' ), in combination with three previously derived facts to derive that Farfalle does not cost \$8.
This derivation is non-trivial because it uses reasoning by contradiction:
%The reasoning behind the scenes can be explained by contradiction as follows: 
 \begin{enumerate}
  \item If Farfalle did cost \$8, then (since Damon did not take Farfalle), Damon did not pay \$8;
  \item If Farfalle did cost \$8, then it did not cost \$16; 
  \item Since Farfalle would not cost \$16 and neither does Capellini or Tagliolini, Rotini must cost \$16;
  \item However, the fact that Rotini costs \$16, while Damon did not pay \$8 is in contradiction with the clue in question;
  \item Hence, Farfalle can not cost \$8.
 \end{enumerate}
 While equally straightforward for a computer, understanding such an indirect proof, using contradiction, in a single step is notably harder for a person; especially compared to the more \textit{forward} explanations of other reasoning steps.
%  Hence, we expanded our tool to -- on demand -- generate a \textit{nested} explanation of this contradiction reasoning.
% It turns out from preliminary analysis of the generated explanation sequence that some steps are still too hard to understand as they combine different constraints and/or multiple clues. 
\bart{DIE LAATSTE SCREENSHOT IS NIET JUIST!
 Dat lijkt een heel oude versie... Kan je aub updaten met de laatste zoals op https://bartbog.github.io/zebra/pasta/ Ook best de ``inconsistency'' niet bovenop een gebruikte clue}
\begin{figure}[t!]
    \includegraphics[width=\linewidth]{figures/incosistency.jpg}
    \caption{A difficult explanation step, including its nested explanation}\label{fig:pasta_diff}
\end{figure}

In this section, we extend the explanation-production problem with the purpose of refining those explanations that are too complex and taking inspiration from counterfactual reasoning.
As such, our problem becomes an explanation-generating problem with 2 levels of abstractions: ``regular'' explanations and ``lower-level'' \textit{nested-explanations}. \tias{lower-level is always 'by contradiction'? Maybe we should be more explicit about that?}

\myparagraph{Nested explanation of a reasoning step}

% To tackle complex inference steps with the lense of counterfactual reasoning, one  \textit{``Can I find another easier way to explain this step using the same facts and constraints by negating the newly derived fact and finding an inconsistency ?''} 


% For the definition of \textit{inconsistency}, we refer back to definition \ref{def:consistent}.


% Tias commented some (filler?) sentences
%The generation of the explanation sequence, as formally defined in Section 4, is initially guided by the cost function $f(E, S, N)$, a proxy for the mental-effort of the explanation-step. 
%To further explain the complex inference steps generated in the explanation sequence, w
\tias{The nested explanation is by definition by contradiction due to the construction of I'0 and that I'n is inconsistent; I think we should be more explicit about this! It is not just nested (e.g. an abstraction level, with smaller steps)?}

When should an explanation-step have a more detailed nested explanation of a newly derived fact? We propose the following principles for an explanation $(E,S,N)$:
%Each explanation $(E,S,N)$ might 
%For each explanation, we 
%Put differently, for every newly derived fact of a given explanation step $(E, S, N)$, we look for an \emph{nested} explanation sequence such that 
\begin{itemize}
 \item a nested explanation starts from the explaining facts $E$, %used in the parent explanation step, 
 augmented with the counterfactual assumption of the newly derived fact $n \in N$; 
 \item at each step, it only uses clues from $S$;
 \item each step is easier to understand (has a strictly lower cost) than the parent explanation $f(E,S,N)$;
 \item from the counterfactual assumption, a contradiction is derived. %; and
 %\item as before, a means to aggregate costs of the different steps to obtain a cost of the sequence to be minimized is assumed to exist.
\end{itemize}

Note that if an explanation steps derives multiple new facts, e.g. $|N| > 1$, then we can compute a nested explanation for each $n_i \in N$.

More formally, we define the concept of \emph{nested-explanation} as follows. 

\begin{definition}
The \textbf{nested-explanation} problem consists of --- given a non-redundant explanation $(E, S, N)$, and a newly derived fact $n \in N$ --- finding a non-redundant explanation sequence 
    \[\langle \ (I_0',(\emptyset,\emptyset,\emptyset)),\ (I_1',(E_1',S_1',N_1')), \dots ,\ (I_n',(E_n',S_n',N_n')) \ \rangle\]
    such that:
    \begin{itemize}
        \item $I_0'$ is the partial interpretation $\{ \neg n_i \wedge E \}$;
        \item $S_i'\subseteq S$ for each $i$;
        \item $f(E_i',S_i',N_i')< f(E, S, N)$ for each $i$; 
        \item $I_n'$ is inconsistent; and
        \item a predefined aggregate over the sequence $\left(f(E_i',S_i',N_i')\right)_{i\leq n}$ is minimised.
    \end{itemize}
\end{definition}

We can hence augment each explanation $(E,S,N)$ with a set of nested explanations if they exist. We next discuss algorithms for computing explanations and nested explanations.
%As for a regular explanation sequence, possible aggregation operators are \textit{max()} and \textit{average()}. 
%\noindent In the following section, we discuss algorithms to generate (nested) explanation sequences; afterwards, we apply them to the domain of logic grid puzzles.


% Ideas : 
% \begin{itemize}
%     \item During analysis of sequence of reasoning steps too hard/ complex to understand 
%     \item 2 levels of abstraction
%     \item Refine explanations using counterfactual reasoning
%     \item 
% \end{itemize}

% We introduce a second
