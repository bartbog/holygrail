A logic grid puzzle  (also known as a Zebra puzzle or Einstein puzzle after Einstein's famous example of this type of puzzle) consists of a set of natural language sentences (from hereon referred to as ``clues'') and (optionally) a set of \emph{entities} occurring in those sentences. 
For instance, our running example contains a clue ``The person who chose arrabiata sauce is either Angie or Elisa'' and (among others) entities ``arrabiata sauce'', ``Angie'' and ``Elisa''. 
The set of entities is sometimes left implicit if it can be derived from the clues, but often it is given in the form of a grid. 
Furthermore, in such a puzzle the set of entities is partitioned into equally sized groups (corresponding to \emph{types}); in our example, at least ``person'' and ``sauce'' are such types. 
The goal of the puzzle is to find relations between each two types such that
\begin{compactitem}
	\item each clue is respected, 
	\item each object of one type is linked to exactly one object of the second type, e.g., each person ordered exactly one sauce (this type of constraint will be referred to as \emph{bijectivity}), and 
	\item the relations are logically linked, e.g., if Angie ordered arrabiata sauce and arrabiata sauce was paired with farfalle, then Angie must also have eaten farfalle (from now on called \emph{transitivity}). 
\end{compactitem}

For now, we assume that a vocabulary with types corresponding to the groups of entities in the clues and binary relations between each two types is given.
We furthermore assume that the interpretation of the types is fixed (and hence all interpretations agree on this). 
Finally, we assume that the clues, as well as the bijectivity and transitivity constraints are given as first-order sentences and that $T_P$ is a theory containing all of these sentences for a given puzzle $P$; we discuss how to obtain this logical form in Section \ref{sec:holistic}.
When a human solves a logic grid puzzle, they typically maintain a grid with all the information obtained so far and use it in combination with the clues to derive new conclusions. In logic terminology, the user maintains a partial interpretation.  
With this in min, the goal underlying our tool is to find a sequence of partial interpretations of the involved relations (e.g., in which it is known that Angie did not choose arrabiata sauce, but it still unknown whether she ordered farfalle) with a 
\emph{justification} (see below) of why each of the steps is correct that is ``as easy to understand as possible''. 
Of course the latter is a subjective matter and quite hard to quantify. Therefore, in this paper, we will use a reasonable approximation thereof. 


\paragraph{Justification of Reasoning Steps.}
As mentioned above, we are searching for a sequence 
\[ I_0 = \emptyset, I_1 = I_0 \cup N_1, \dots , I_n = I_{n-1}\cup N_n\]
where $I_i$ represents the state of the grid at each point in time and $N_i$ represents the newly derived information. 
Furthermore, it is important that each reasoning step be accompanied with a \emph{justification}. By that we mean a tuple $(E_i,S_i)$ such that: 
\begin{compactitem}
	\item $E_i\subseteq I_i$ (i.e., the explaining facts are a subset of what was previously derived),
	\item $S_i \subseteq T_P$ (i.e., only some of the clues and implicit constraints are used), and 
	\item $S_i \cup E_i \entails N_i$ (i.e., all newly derived information indeed follows from this justification).
\end{compactitem}
A first observation related to this definition is that it nowhere specifies \emph{quality} of the justifications, this manifests at least in two forms already. First of all, any superset of a justification is a justification itself (it seems clear that a bare minimal demand on our justifications should be that they are subset-minimal), and secondly, since since logic grid puzzles have a unique solution, say $Sol$ the sequence 
\[I_0, Sol\]
with justification $(\emptyset,T_P)$ always satisfies this definition. That justification simply states ``this is the solution because, well, it is'' and is of course extremely uninformative. However, the current definition only establishes what constitutes a correct justification, quality of justifications is studied later on. 

Another observation is that the problem checking whether $(E_i,S_i)$ explains $N_i$ is definitely in co-NP since this problem can be performed by verifying that $S_i \land \lnot N_i$ has no models more precise than $E_i$ and hence is an instance of the negation of a model expansion problem \cite{ternovskaMXcomplexity}. 
Furthermore, the task of finding a \emph{subset-minimal} justification can easily be cast, after reifying the involved constraints as a second-order problem of the form
\[\exists S_i\subseteq T_P, E_i\subseteq I_i: (\forall I: I\models S_i\land E_i \Rightarrow N_i) \land \lnot \exists S_i'\subseteq S_i, E_i'\subseteq E_i: \forall ... \]
\bart{Not sure how valuable it is to put this here.}
In principle our problem of finding subset-minimal (or even, see the next paragarph, cost-optimal) justifications could be solved by specifying it in such a way in second-order logic and subsequently finding models for it, e.g. by a reduction to QBF \cite{kr/BogaertsTS16,kr/vanderHallenJ18}. 
However, since this is already an $\exists\forall\exists SO$ specification, we expect this approach not be feasible (this expectation remains to be verified in future work). 



\paragraph{Simplicity of reasoning steps.}
While subset-minimality appears to be a necessary condition for acceptable justifications, it certainly is not a sufficient condition. 
Indeed, at a certain point in the explanation sequence, many different subset-minimal justifications can exist and not all of them are equally simple. 
Compare for instance using a single clue to derive a new fact with using the combination of two clues and five previously derived facts to find a new fact. 
To approximate of how easy to understand a justification is (i.e., a single transition in the above described sequence), we start from the simple cognitive idea \bart{can we cite this somewhere? } that (in general) the fewer things a human needs to have in memory simultaneously, the easier the task at hand is. 
Hence, as a measure of difficulty we propose to use a weight function in terms of \textbf{the total number of clues, bijectivity and transitivity constraints, and previously derived facts} needed to derive a new fact. \bart{In fact ,we do not exactly use this measure, since we do not allow combining two clues if there exists some explanation that only uses one}
The reader should be advised that this is quite a rough approximation; for instance certain clues can be easier than others to reason about (e.g., compare ``Claudia did not choose puttanesca sauce'' with ``The person who ordered rotini is either the person who paid \$8 more than Damon or the person who paid \$8 less than Damon'') or it might be that humans perceive reasoning about clues in general as easier or harder than reasoning about the implicit (bijectivity and transitivity) constraints presents in logic grid puzzles. While researching better measures is an interesting topic, it falls out of the scope of the current paper. Moreover, many ideas of the current work remain valid when the actual measure is changed. 
Our observatoin from below, that using second-order logic tools such as e.g. \cite{proB,kr/BogaertsTS16} to find cost-optimal justifications is an option remains valid as long as the cost-functoin is expressible in (a sufficient extension of SO). Yet, due the high complexity, is not a direction we explored. 
\bart{Actually, I would really like to try this sometimes. The complexity argument is valid. But since we have small domains it is actually not so relevant... Maybe it works well. In that case it would yield good explanations!  }


\paragraph{Simple sequence vs simple steps}
In the above, we focused on generating and defining understandability of a single step in the reasoning process. 
However, in its most general form, we would like to optimize the understandability of the entire sequence of explanations. 
For this, even defining a measure seems to be a very hard task (for instance, is the understandability of a sequence related to its most difficult step or to its average difficulty? Sometimes even the ordering of the steps might make a difference for humans, even though the actual steps are the same, ...). 
Furthermore, even if we fix a measure, the problem of holistically optimizing a sequence of explanation steps is much harder than optimizing a single step since there are exponentially more sequences. 
Therefore, in the current paper, we take a greedy approach where at each step, the best next possible explanation is chosen, without taking global optimality of the sequence in mind. The results we obtain this way are satisfying. 
\bart{And already say something about postprocessing?}


% The grand goal underlying our tool is to find, given a logic grid puzzle (of which we assume it is given in some logical form for now; we revisit this in Section \ref{sec:holistic}), to find a sequence of partial assignments of variables (e.g., where it is already determined that certain entities are linked (or not linked) to which other entities) that is ``as easy to understand'' as possible.  
% Of course the latter is quite a vague concept and hard to find an objective measure for. However, we 
% The larger problem

