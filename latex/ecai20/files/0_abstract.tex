We explore the problem of step-wise explaining how to solve logic problems, for example logic grid puzzle. The main challenge is that reasoning engines can freely combine all knowledge in their knowledge base to make derivations. In contrast, we want explanations to be simple and cognitively easy, so that a human can easily verify the reasoning step, and learn how to make similar reasoning steps.
We identify the problem of finding a good ordering of self-contained reasoning steps. Different interpretations of good ordering as well as self-containedness of a reasoning step are discussed. To make the search for a good ordering feasible in reasonable time, we propose an iterative refinement approach where minimal unsat core's over well-defined decompositions of the problem are searched. Our experiments show the feasibility of the approach in terms of the ordering and size of the explanations given as well as the computation time needed.
