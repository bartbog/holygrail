The first two considerations from the previous section lead to the following definition. 

\begin{definition}
   Let $\formula$ be a formula, $f:2^{\formula} \to \nat$ a cost function and  $p$ a predicate $p: 2^{\formula}\to \{\ltrue,\lfalse\}$. We call %a set $U\subseteq \formulag$ a \emph{$p$-constrained $f$-OUS} of \formulag ($(p,f)$-OUS) \tias{what with the OCUS name here?} \bart{I propsoe to say. We call 
    $\m{S} \subseteq \formula$ an OCUS of \formula (with respect to $f$ and $p$) if \begin{compactitem}                                      
      \item $\m{S}$ is unsatisfiable,
      \item $p(\m{S})$ is true
      \item all other unsatisfiable $\m{U}'\subseteq \formula$ with $p(\m{U}')=\ltrue$ satisfy $f(\m{U}')\geq f(\m{S})$.
    \end{compactitem}
\end{definition}

Rephrased in these terms, the task of the procedure \onestep is to compute an OCUS of the formula $\formula := \formulac\land I\land \overline{\Iend\setminus I}$ with $p$ the predicate that holds for subsets  that contain exactly one literal of $\overline{\Iend}$, see \cref{alg:oneStepOCUS}. 
%In the rest of this paper, we study (incremental) algorithms for computing an OCUS. 


In order to compute an OCUS of a given formula, we propose to build on the hitting set duality of \cref{prop:MCS-MUS-hittingset}. 
For this, we will assume to have access to a solver \cohs that can compute hitting sets of a given collection of sets that are \emph{optimal} (w.r.t.\ a given cost function $f$) among all hitting sets \emph{satisfying a condition $p$}. 
The choice of the underlying hitting set solver will thus determine which types of cost functions and constraints are possible. 
In our implementation we use a cost function $f$ as well as a condition $p$ that can easily be encoded as linear constraints, thus allowing the use of highly optimized mixed integer programming solvers. The \cohs formulation is as follows:
{\small
\begin{align*}
  maximize_X \quad & f(X)\\
  s.t. \quad & p(X) \\
       & sum(H) \geq 1, \quad &\forall H \in \setstohit \\
       & x \in \{0,1\}, \quad &\forall x \in X
\end{align*}}
%\bart{This is not what the reviewers asked for! They asked for MIP models of our ``arbitrary objective functions''. A mip encoding of a generic hitting set problem with only some ``at least one'' constraints is not going to help us, I think. }
% well, its not arbitrary but linear, and it is a weighted sum; will have to do
where $X$ is a set of MIP decision variables, one for every literal that appears in $f$, $p$ or \setstohit. In our case, $p$ is expressed as $\sum_{x \in \overline{\Iend\setminus I}} x = 1$ and $f$ is a weighted sum over the literals. For example, literals of known facts can be given small weights and literals that are indicator variables for constraints large weights, such that explanations are penalized for including many constraints when relevant facts are directly available.



\newcommand\onestepo{\ensuremath{\call{explain-One-Step-ocus}}\xspace}
\begin{algorithm}[t]
  \DontPrintSemicolon
  
  \caption{$\onestepo(\formulac,f,I,\Iend)$}
  \label{alg:oneStepOCUS}
  $p \leftarrow$ exactly one of $\overline{\Iend\setminus I}$\;
  \Return{$\comus(\formulac\land I\land \overline{\Iend\setminus I}, f, p)$} 
\end{algorithm}
\begin{algorithm}[t]
  \DontPrintSemicolon
%  $\setstohit  \gets \emptyset$ \; %\label{omus-line1} 
  \While{true}{
    $\m{S} \gets \cohs(\setstohit,f,p) $  \;%\tcp*{\small Find \textb    $\setstohit  \gets \setstohit  \cup \{  \formula \setminus \F''\}$ \;
% f{optimal} solution}
    % \tcp{\small set with all unique clauses from hitting set}
%     (sat?, $\kappa$) $\gets$ \texttt{SatSolver}($hs$)\;
    % \tcp{If SAT, $\kappa$ contains the satisfying truth assignment}
    % \tcp{IF UNSAT, $hs$ is the OUS }
    \If{ $\lnot \sat(\m{S})$}{
      \Return{$\m{S}$} \;
    }
    $\m{S} \gets  \grow(\m{S},\F) $ \label{line:grow}\;
    $\setstohit  \gets \setstohit  \cup \{  \formula \setminus \m{S}\}$ \;
  }
  \caption{$\comus(\formula,f,p)$ }
  \label{alg:comus}
\end{algorithm}


%\tias{I would not show the above one as it is rather vague \bart{I would disagree with the vagueness. It makes abstraction of several things (what is $p$? what is $f$? How is Grow and CondOptHS implemented? But in my opinion that is good, since it shows close relation to the basic OUS algo as well as illustrating what is really going on and modularity.}, but immediately rewrite it as Alg2 the singleStepExplain:}
%\bart{I would avoid that :-) That way we mix up ``how to compute constrained OUSs?'' with ``how to compute explanations using constrained OUSs?''. These are two different concerns. We should show that we also tackle the first .  That way, our new ``singlestepexplain2'' will also look a lot simpler than singleStepExplain1 (if we use one oracle call to cOUS}

%\begin{algorithm}[ht]
%  \caption{$\call{ExplainCSPcOUS}({\cal C},f)$}
%  \label{alg:explainCSPcOUS}
%$E \gets \langle \rangle$\;
%$I_{end} \gets optimalPropagate({\cal C})$\;
%$\formulag \gets {\cal C} \cup I_{end} \cup \overline{\Iend}$\;
%$\setstohit \gets \{\formulag \setminus \{{\cal C} \cup I_{end}\}\}$\;
%// preseeding\\
%\For{$l \in I_{end}:$}{
%  $\setstohit \gets \setstohit \cup \{\formulag \setminus \grow(-l,\formulag)\} $\;
%}
%$I \gets \emptyset$\;
%$p \gets \{$exactly one of $\overline{\Iend}$ in the hitting set$\}$\; %, none of $I_{end}$ can be in the hitting set$\}$\;
%
%\While{$I \neq I_{end}$}{
%	update $p$ such that none of $\{I_{end} \setminus I\}$ and none of $\bar{I}$ can be in the hitting set\;
%    $\m{S} \gets \comus(\formulag,f,p,\setstohit)$\;
%	$I_{\mathit{best}} \gets I\cap \m{S}$\;
%    ${\cal C}_{\mathit{best}}\gets{\cal C}\cap \m{S}$\;
%	$N_{\mathit{best}} \gets \{I_{end} \setminus I\} \cap optimalPropagate(\m{S}) $\;
%	add $\{I_{\mathit{best}} \wedge {\cal C}_{\mathit{best}} \implies N_{\mathit{best}}\}$ to $E$\;
%	$I \gets I \cup N_{\mathit{best}}$\; 
%  }
%\Return{E}\;
%\end{algorithm}
Our generic algorithm for computing OCUSs is depicted in \cref{alg:comus}. It combines the hitting set-based approach for MUSes of \cite{ignatiev2015smallest} with the use of a MIP solver for (weighted) hitting sets as proposed for maximum satisfiability \cite{davies}. The key novelty is the ability to add structural constraints to the hitting set solver, without impacting the duality principles of \cref{prop:MCS-MUS-hittingset} as we will show.

Taking abstraction of \cref{line:grow} for a moment, 
the algorithm alternates calls to a hitting set solver with calls to a \sat oracle on a subset $\m{S}$ of $\formula$. 
In case the \sat oracle returns true, i.e., the subset $\m{S}$ is satisfiable, the complement of $\m{S}$ is a correction subset and is added to \setstohit. In this way, the hitting set size always grow and a hitting set $\m{S}$ will always be a subset of $\formula$.

Instead of directly adding the complement of $\m{S}$ to \setstohit as done in \cite{ignatiev2015smallest}, our algorithm includes a call to \grow, which extends $\m{S}$ into a larger subset of $\formula$ that is still satisfiable (if possible).
%\tias{here base grow impls?} \bart{Your next sentence is enough for me here. Alternatively we can in one stentence say that we consider a greedy and a maxsat-based implementation? }
We discuss the different possible implementations of \grow later and evaluate their performance in \cref{sec:experiments}. 

Soundness and completeness of the proposal follow from the fact that all sets added to \setstohit are correction subsets, and \cref{thm:soundcomplete}, which states that what is returned is indeed a solution and that a solution will be found if it exists. 
 
\begin{theorem}\label{thm:soundcomplete}
  Let $\m{H}$ be a set of correction subsets of \mcses{\formula}. 
  If $\m{S}$ is a hitting set of \m{H} that is $f$-optimal among the hitting sets of \m{H} satisfying a predicate $p$, and  $\m{S}$ is unsatisfiable, then $\m{S}$ is an OCUS of \formula. 
  
  If  $\m{H}$ has no hitting sets satisfying $p$, then $\formula$ has no OCUSs.
\end{theorem}
\begin{proof}
For the first claim, it is clear that $\m{S}$ is unsatisfiable and satisfies $p$. Hence all we need to show is $f$-optimality of $\m{S}$.
  If some other unsatisfiable subset $\m{U}'$ that satisfies $p$ would exists with $f(\m{U}')\leq f(\m{S})$, we know that $\m{U}'$ would hit every minimal correction set of \m{F}, and hence also every set in \m{H} (since every correction set is the superset of a minimal correction set).
  Since $\m{S}$ is $f$-optimal among hitting sets of $\m{H}$ satisfying $p$ and $\m{U}'$ also hits $\m{H}$ and satisfies $p$, it must thus be that $f(\m{S})=f(\m{U}')$. 
%  

The second claim immediately follows from \cref{prop:MCS-MUS-hittingset} and the fact that an OCUS is an unsatisfiable subset of $\formula$. 
\end{proof}


Perhaps surprisingly, correctness of the proposed algorithm does \emph{not} depend on monotonicity properties of $f$ nor $p$. In principle, any (computable) cost function and condition on the unsatisfiable subsets can be used. In practice however, one is bound by limitations of the chosen hitting set solver. 


% Now, since the search for optimal hitting sets is --- in implicit hitting set algorithms --- usually done with a MIP solver, it suffices to express the predicate $p$ as constraints on the MIP. Since the variables of the MIP encoding represent inclusion of certain constraints in the unsatisfiable subset, this is simple for  the 3 constraints that we need to obtain meaningful explanations. %needed to have meaningful in practice only predicates $p$ that can easily be encoded in MIP are useful. In such cases, we can directly use the MIP solver to implement \cohs as well. 

% \paragraph{Application to Explanations}
% %To apply this idea to the context of explanations, we note that at each step, the current interpretation, will be fixed. 
% %At each step, we are looking for an OUS that contains \emph{exactly one} negation of a derivable literal. 
% %Such an exactly-one constraint is easily expressible in MIP.
% %Furthermore, also the ``subtheory constraint'', as introduced for incremental MUS solving can be expressed in MIP. Namely, in \cref{sec:incremental}, we assumed that each OUS call would be done given a subtheory of the original theory. However, constraints of the form ``the OUS should be a subset of the given set \formula'' are easily expressible in MIP as well. 
% %As such, the idea of constrained OUS computation is actually more general than the formalization of incremental OUS. 
% % 
% Given such a constrained OUS algorithm, the procedure to find the single best explanation step now simplifies to \cref{alg:singleStepExplain3}.
% 
% \begin{algorithm}[t]
%   \caption{$\call{bestStep--c-OUS}({\cal C},f,I,I_{end})$}
%   \label{alg:singleStepExplain3}
% $\formulag \gets {\cal C} \cup I_{end} \cup \overline{\Iend}$\;
% set $p$ such that exactly one of $\overline{\Iend}$ in the hitting set \textit{and} none of $\{I_{end} \setminus I\}$ \textit{and} none of $\bar{I}$ can be in the hitting set\;
% \Return{$\comus(\formulag,f,p)$}\;
% \end{algorithm}

% \tias{hard/soft temporarily hidden}
% \ignore{

