\section{Types}
\label{sec:types}
In natural language, it is possible to construct sentences that are grammatically correct but without meaning. E.g. ``The grass is drinking the house''. The grass is not something that can drink and a house is not something that can be drunk. We say the sentence is badly typed. Based on grammar alone, we can never exclude these sentences. Therefore, we add types to the framework.

Concretely, we add a feature \textit{type} to most words and phrases to indicate their type. Similarly to the feature \textit{number} that some words and phrases have. The feature \textit{number} indicates whether a word or phrase is singular or plural. In a sentence, the \textit{number} of the noun phrase and the verb phrase must unify, i.e. the subject and the verb must agree in number. Similarly to this, the \textit{type} of the noun phrase and the verb phrase must unify.

In this paper we use a very basic type system. There are a number of basic types and a \textit{pair} type constructor that takes two basic types. E.g. a noun has a basic type, a transitive verb a pair of types: one for its subject and one for its object. Also phrases get types. A noun phrase gets a basic type. The same goes for a verb phrase. In the grammar we then express that the type of the noun phrase and the verb phrase should unify when they make a sentence. This excludes badly typed sentences from being accepted.

We also use these types in the semantics to indicate the types of the logical variables and of predicates. This allows the system to translate to a typed logic.

As indicated earlier, most words (like noun, verb, ...) also get a type in the lexicon. In this paper we explored a form of type inference. We assume that every word has exactly one type but that is not explicitly given to the system. We then search the types of all words. Based on these types, we can group the domain elements (represented by a proper noun) per domain (represented by a type), i.e. we can infer that ``France'' and ``Italy'' are from the same domain (without necessarily knowing that they are countries).

The search for the types of all words gets as input the number of domains in the puzzle (related to the number of base types) and some type constraints (from the translation of the clues into logic, based on the principle of one type per word). If many synonyms are used, the system enters an interactive mode and asks the user some linguistic questions that can be rewritten as ``Is ... a meaningful sentence?'' until the types are unified enough.

This process fails if (and only if) a certain domain always occurs as part of noun phrases with an unknown relation (e.g. ``the 2008 graduate''). In such a scenario, the system cannot fallback on a linguistic question and therefore asks the user if two proper nouns are of the same type. This is the exact question the system was supposed to solve.

The described system can thus correctly derive which domain elements belong together based on type constraints and the answers to some linguistic questions. Only when they do not provide enough information, is the user asked to help identify the elements that belong together.
