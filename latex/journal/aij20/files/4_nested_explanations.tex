When we implemented the ideas from the previous section and applied them to logic grid puzzles, as explained in Section \ref{sec:zebra}, we noticed that 
for the most \textit{difficult} puzzles, some explanation steps were still quite hard to understand.
An example is depicted in Figure \ref{fig:pasta_diff}.
It uses a complicated (disjunctive) clue (``The person who ordered Rotini is either the person who paid \$8 more than Damon or the person who paid \$8 less than Damon'' ), in combination with three previously derived facts to derive that Farfalle does not cost \$8.
The reasoning behind the scenes can be explained by contradiction as follows: 
 \begin{enumerate}
  \item If Farfalle did cost \$8, then (since Damon did not take Farfalle), Damon did not pay \$8;
  \item If Farfalle did cost \$8, then it did not cost \$16; 
  \item Since Farfalle does not cost \$16 and neither does Capellini or Tagliolini, Rotini must cost \$16;
  \item However, the fact that Rotini costs \$16, while Damon did not pay \$8 is in contradiction with the clue in question. 
 \end{enumerate}
 While equally straightforward for a computer, understanding such an indirect proof, using contradiction, in a single step is notably harder for a person than the more common explanation steps our tool generates.
%  Hence, we expanded our tool to -- on demand -- generate a \textit{nested} explanation of this contradiction reasoning.
% It turns out from preliminary analysis of the generated explanation sequence that some steps are still too hard to understand as they combine different constraints and/or multiple clues. 
\bart{DIE LAATSTE SCREENSHOT IS NIET JUIST!
 Dat lijkt een heel oude versie... Kan je aub updaten met de laatste zoals op https://bartbog.github.io/zebra/pasta/ Ook best de ``inconsistency'' niet bovenop een gebruikte clue}
\begin{figure}[t!]
    \includegraphics[width=\linewidth]{figures/nested-explanation.png}
    \caption{A difficult explanation step}\label{fig:pasta_diff}
\end{figure}

In this section, we extend the explanation-production problem with the purpose of refining those explanations that are too complex and taking inspiration from counterfactual reasoning.
As such, our problem becomes an explanation-generating problem with 2 levels of abstractions: ``regular'' explanations and ``lower-level'' \textit{nested-explanations}.

\myparagraph{Nested explanation sequence production}

% To tackle complex inference steps with the lense of counterfactual reasoning, one  \textit{``Can I find another easier way to explain this step using the same facts and constraints by negating the newly derived fact and finding an inconsistency ?''} 


% For the definition of \textit{inconsistency}, we refer back to definition \ref{def:consistent}.


The generation of the explanation sequence, as formally defined in Section 4, is initially guided by the cost function $f(E, S, N)$, a proxy for the mental-effort of the explanation-step. 
To further explain the complex inference steps generated in the explanation sequence, we define the concept of \emph{nested-explanation} as follows. 

\begin{definition}
The \textbf{nested-explanation} problem consists of --- given a non-redundant explanation $(E, S, N)$, and a newly derived fact $n \in N$ --- finding a non-redundant explanation sequence 
    \[\langle \ (I_0',(\emptyset,\emptyset,\emptyset)),\ (I_1',(E_1',S_1',N_1')), \dots ,\ (I_n',(E_n',S_n',N_n')) \ \rangle\]
    such that:
    \begin{itemize}
        \item $I_0'$ is the partial interpretation $\{ \neg n_i \wedge E \}$;
        \item $S_i'\subseteq S$ for each $i$;
        \item $f(E_i',S_i',N_i')< f(E, S, N)$ for each $i$; 
        \item $I_n'$ is inconsistent; and
        \item a predefined aggregate over the sequence $\left(f(E_i',S_i',N_i')\right)_{i\leq n}$ is minimised..
    \end{itemize}
\end{definition}

Put differently, for every newly derived fact of a given explanation step $(E, S, N)$, we look for an \emph{nested} explanation sequence such that 
\begin{itemize}
 \item it starts only from the assumptions used in the given explanation step, augmented with the counterfactual assumption that the derivation does not hold; 
 \item at each step, only uses clues from $S$;
 \item each step is easier to understand (has a strictly lower cost) than the high-level explanation;
 \item from the counterfactual assumption, a contradiction is derived; and
 \item as before, a means to aggregate costs of the different steps to obtain a cost of the sequence to be minimized is assumed to exist.
\end{itemize}

In the next section, we discuss algorithms to generate (nested) explanation sequences; afterwards, we apply them to the field of logic grid puzzles.


% Ideas : 
% \begin{itemize}
%     \item During analysis of sequence of reasoning steps too hard/ complex to understand 
%     \item 2 levels of abstraction
%     \item Refine explanations using counterfactual reasoning
%     \item 
% \end{itemize}

% We introduce a second
