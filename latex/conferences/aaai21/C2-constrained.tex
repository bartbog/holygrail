The next question we tackle is, given \fall from the previous section, would it be possible to replace the entire for-loop in \cref{alg:explainSingleStep} by a single \omus call.
It would be tempting to attempt this by a single call to 
\[\omus(\formulag\cup I\cup\{\lnot l\mid \formulag \land I\models l\land l\not\in I)\]
\tias{difficult to read, introduce barI or smth... also, a missing curly brace but difficult to read}
however this would not result in explanations in the sense of \citet{ecai/BogaertsGCG20}, as the following example illustrates. 
% To see this consider the following example: 
\begin{example}
Assume \begin{align*}
         \formulag &= \{p\lor q, \lnot p \lor r, \lnot p \lor \lnot r, \lnot q\lor r, \lnot p \lor q \}\text{ and }\\
         I &= \emptyset
       \end{align*}
       and thus
$         I_{\mathit{end}} = \{ \lnot p, q, r\}.
$. 
In that case, 
\[\formulag\cup \lnot I_{\mathit{end}} = \{p\lor q, \lnot p \lor r, \lnot p \lor \lnot r, \lnot q\lor r, \lnot p \lor q , p,\lnot q,\lnot r \}\]
has several cardinality-minimal OUSs, for instance 
\begin{align*}
X_1 &=    \{\lnot p \lor r, \lnot p \lor \lnot r, p\}\text{ and}\\
X_2 &= \{\lnot p \lor q ,  p, \lnot q\}.
\end{align*}
However, in the context of explanations, out of these two only $X_1$ would be considered to induce a good explanation: it represents the fact that the two constraints $\lnot p \lor r$ and $ \lnot p \lor \lnot r$ together entail $\lnot p$ (which can easily be seen by applying the resolution rule). However, $X_2$ does not have such an interpretation: it merely shows that he constraint $\lnot p \lor q$ entails that either $p$ should be false or $q$ should be true, which is quite uninformative. 
\end{example}
\tias{This surprisingly informal. our implications need to use elements of $I$ and elements of $\bar{I}$, however calling OUS on G and I and barI leads to trivial l negl. So to get our desired implications, we need two constraints: 1) can only have one element of barI, 2) can only use elements of $I$ that are already explained. Both restrict the syntax of the OUS, but they do not affect satisfiability and hence nor that a satisfiable subset can be grown and then turned into an mcs. So, we only need to modify the hitting set computation part. We do this by 1) adding a constraint to the MIP, 2) updating the weights of the objective function such that no unexplained I can be found. smth like this?}
\bart{There are two points here:
\begin{itemize}
  \item Adding complete I and barI yields a trivial MUS is one point.
  \item However, in a singlestepexplain, the simplest way to go would be to add I-sofar and barI-tobederived. There, teh trivial inconsistency does not show up
  What I tried to illustrate in the example is that *that* also doesnt work. THat getting *exactly one* literal from barI-tobederived is really crucial. Should be made more clear. 
\end{itemize}
}


The previous example shows that a naive \omus call with a large enough theory, would not yield valuable explanations.
Instead, we would be interested in searching MUSs that are \emph{optimal} among those MUSs satisfying a certain property (in our case this property is ``containing exactly one negation of a consequence literal''). 
Phrasing this in a generic setting results in the following definition.

\begin{definition}
    If $\fall$ is a formula, $f:2^{\fall} \to \nat$ a cost function and  $p$ a predicate $p: 2^{\fall}\to \{\ltrue,\lfalse\}$, then we call a set $U\subseteq \fall$ a \emph{$p$-constrained $f$-OUS} ($(p,f)$-OUS) if \begin{itemize}                                                                                                                                                                                                                         
    \item $U$ is unsatisfiable,
    \item $p(U)$ is true
    \item for all other $U'\subseteq \fall$ with $p(U')=\ltrue$, it holds that $f(U')\geq f(U)$.                                                                                                                                                                                                                         \end{itemize}
\end{definition}

The problem at hand is thus to compute a $(p,f)$-OUS of a given formula. 
To tackle this challenge, we propose a modification of \cref{alg:omus}, as described in \cref{alg:comus}. 
As can be seen, the condition $p$ is simply passed to the procedure \cohs, which, in contrast to \ohs generates a hitting set that is optimal \emph{among the hitting sets satisfying $p$}. Correctness of the algorithm now follows from the fact that -- as before -- all sets added to \setstohit are correction subsets (and that every MUS must thus hit all sets in \setstohit) and \cref{prop:K2}, which guarantees that when the algorithm returns $\F'$, a good solution is indeed found.  

\begin{algorithm}[ht]
  \DontPrintSemicolon
  $\setstohit  \gets \emptyset$ \; %\label{omus-line1} 
  \While{true}{
    $\F' \gets \cohs(\setstohit,f,p) $  \;%\tcp*{\small Find \textb    $\setstohit  \gets \setstohit  \cup \{  \formula \setminus \F''\}$ \;
% f{optimal} solution}
    % \tcp{\small set with all unique clauses from hitting set}
%     (sat?, $\kappa$) $\gets$ \texttt{SatSolver}($hs$)\;
    % \tcp{If SAT, $\kappa$ contains the satisfying truth assignment}
    % \tcp{IF UNSAT, $hs$ is the OUS }
    \If{ $\lnot \sat(\F')$}{
      \Return{$\F'$} \;
    }
    $\F'' \gets  \grow(\F',\F) $\;
    $\setstohit  \gets \setstohit  \cup \{  \formula \setminus \F''\}$ \;
  }
  \caption{$\comus(\formula,f,p)$ }
  \label{alg:comus}
\end{algorithm}
\tias{I would not show the above one as it is rather vague \bart{I would disagree with the vagueness. It makes abstraction of several things (what is $p$? what is $f$? How is Grow and CondOptHS implemented? But in my opinion that is good, since it shows close relation to the basic OUS algo as well as illustrating what is really going on and modularity.}, but immediately rewrite it as Alg2 the singleStepExplain:}
\bart{I would avoid that :-) That way we mix up ``how to compute constrained OUSs?'' with ``how to compute explanations using constrained OUSs?''. These are two different concerns. We should show that we also tackle the first .  That way, our new ``singlestepexplain2'' will also look a lot simpler than singleStepExplain1 (if we use one oracle call to cOUS}

\begin{algorithm}[ht]
$\setstohit  \gets \emptyset$ \;
preseeding:\\
\For{$l \in I_{end}:$}{
  $\setstohit \gets \setstohit \cup \grow(-l,\F) $\;
}
the constrained OUS loop:
  \While{true}{
    some appropriate modifications to $f$ in terms of infinity values... \\
    p = $\sum \bar{I} == 1$ or however this can be more nicely written \\
    $\F' \gets \cohs(\setstohit,f,p) $  \;%\tcp*{\small Find \textb   

    \If{ $\lnot \sat(\F')$}{
      \Return{$\F'$} \;
    }
    $\F'' \gets  \grow(\F',\F) $\;
    $\setstohit  \gets \setstohit  \cup \{  \formula \setminus \F''\}$ \;
  }
    \caption{$\call{SingleStepExplain2}(\formulag,f,I)$}
  \label{alg:singleStepExplain2}
  \label{alg:explainSingleStep2}
\end{algorithm}


\begin{proposition}\label{prop:K2}
  Let $\m{H}$ be a set of correction subsets of \mcses{\formula}. 
  If $\m{U}$ is a hitting set of \m{H} that is $f$-optimal among the hitting sets of \m{H} satisfying a predicate $p$, and  $\m{U}$ is unsatisfiable, then $\m{U}$ is a $(p,f)$-OUS of \formula. 
\end{proposition}

Now, since the search for optimal hitting sets is --- in implicit hitting set algorithms --- usually done with a MIP solver, in practice only predicates $p$ that can easily be encoded in MIP are useful. In such cases, we can directly use the MIP solver to implement \cohs as well. 

\paragraph{Application to Explanations}
To apply this idea to the context of explanations, we note that at each step, the current interpretation, will be fixed. 
At each step, we are looking for an OUS that contains \emph{exactly one} negation of a derivable literal. 
Such an exactly-one constraint is easily expressible in MIP.
Furthermore, also the ``subtheory constraint'', as introduced for incremental MUS solving can be expressed in MIP. Namely, in \cref{sec:incremental}, we assumed that each OUS call would be done given a subtheory of the original theory. However, constraints of the form ``the OUS should be a subset of the given set \formula'' are easily expressible in MIP as well. 
As such, the idea of constrained OUS computation is actually more general than the formalization of incremental OUS. 


\paragraph{Using Constraints to Encode Domain Knowledge}
These constraints on OUSs can not only be used to restrict the set of solutions we are interested in, but also to improve the solver performance by encoding domain knowledge.
Indeed, if we know that all ``good'' OUSs will satisfy certain constraints, or if we know that it suffices to search for OUSs satisfying certain constraints (because each OUS can easily be extended to one such OUS),  we can also encode that knowledge in $p$, thereby restricting the possible options of the hitting set solver, aiming to improve overall performance of the algorithm. 

In the explanation application, we encountered this phenomenon as follows. 
The clues to be used in explanations were high-level (first-order) constraints. They were translated into clauses, using among other, a Tseitin transformation.
Hence, in the end the transformation of a single high-level clue consists of several clauses, of which some are definitions of newly introduced variables. 
Now, the associated cost function was only concerned with the issue ``\emph{was a certain clue used or not?}'', which translates at the lower level to ``\emph{does the OUS contain a clause from the translation of the clue?}''.
Using such a cost function means that the compute the cost of an OUS, it does not matter if a single, or all all clauses corresponding to a given clue are used. As such, we might as well include all of them. This knowledge can easily be encoded in $p$ as well. 

An alternative view on the same property is that we can \emph{reify} the high level constraint by considering a Tseitin variable defining satisfaction of the entire constraint. 
We can then to $p$ add the property that all Tseitin definitions are \emph{hard constraints}, in the sense that they always have to be included in any OUS (and thus hitting set), while only the truth/falsity of the single Tseitin variable is considered to be a clause that can be enabled/disabled by the hitting set algorithm. 
This variable then represent whether or not the high level constraint is active.
It is easy to see that there is a one to one correspondence between the OUSs produced by the two approaches. In our implementation, we opted for the latter because of its simplicity. 


 
