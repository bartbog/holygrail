{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import pandas as pd\n",
    "from statistics import mean, median, stdev, variance\n",
    "import qgrid\n",
    "from enum import Enum, IntEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder paths\n",
    "results_folder = 'data/benchmark/'\n",
    "cnf_path = 'data/cnf-instances/'\n",
    "wcnf_path = 'data/wcnf-instances/'\n",
    "\n",
    "\n",
    "\n",
    "# problem names\n",
    "# p = set(f_name for f_name in gurobi_ext4_files)\n",
    "f_paths = None\n",
    "\n",
    "# extension\n",
    "if os.path.exists(results_folder):\n",
    "    f_paths = [f\"{results_folder}{f}\" for f in os.listdir(results_folder) if f.endswith('.json')]\n",
    "   \n",
    "cnf_files = [f.replace('.cnf', '') for f in os.listdir(cnf_path) if f.endswith('.cnf')]\n",
    "wcnf_files = [f.replace('.wcnf', '') for f in os.listdir(wcnf_path) if f.endswith('.wcnf')]\n",
    "\n",
    "cnf_problems = [f for f in f_paths if any(cnf_file in f for cnf_file in cnf_files)]\n",
    "wcnf_problems = [f for f in f_paths if any(wcnf_file in f for wcnf_file in wcnf_files)]\n",
    "#print(f_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1af1f1bf94a48ffa18d6ed00dacb0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ClauseCounting(IntEnum):\n",
    "    VALIDATED = 1\n",
    "    WEIGHTS = 2\n",
    "    WEIGHTED_UNASSIGNED = 3\n",
    "\n",
    "class ClauseSorting(IntEnum):\n",
    "    IGNORE = 0\n",
    "    WEIGHTS = 1\n",
    "    UNASSIGNED = 2\n",
    "    WEIGHTED_UNASSIGNED = 3\n",
    "    LITERAL_ORDERING = 4\n",
    "\n",
    "class BestLiteral(IntEnum):\n",
    "    COUNT_PURE_ONLY = 1\n",
    "    COUNT_POLARITY = 2\n",
    "\n",
    "class UnitLiteral(IntEnum):\n",
    "    IGNORE = 0\n",
    "    RANDOM = 1\n",
    "    SINGLE_POLARITY = 2\n",
    "    POLARITY = 3\n",
    "    IMMEDIATE = 4\n",
    "\n",
    "class SatModel(IntEnum):\n",
    "    RANDOM = 1\n",
    "    BEST_CLAUSES_VALIDATED = 2\n",
    "    BEST_CLAUSE_WEIGHTS_COVERAGE = 3\n",
    "    BEST_WEIGHTED_UNASSIGNED_CLAUSE_COVERAGE = 4\n",
    "    ALL = 5\n",
    "\n",
    "\n",
    "\n",
    "data = {'p':  [],\n",
    "        'solver': [],\n",
    "        'type':[],\n",
    "        'ext' : [],\n",
    "        'clauses' : [],\n",
    "        'steps': [],\n",
    "        'total time [s]': [],\n",
    "        '% hs [s]' : [],\n",
    "        '% sat [s]' : [],\n",
    "        '% grow [s]':[],\n",
    "        's_hs':[],\n",
    "        's_grow':[],\n",
    "        'avg_s_hs':[],\n",
    "        'avg_s_grow':[],\n",
    "        'OMUS':[],\n",
    "        \"count_clauses\": [],\n",
    "        \"best_unit_literal\": [],\n",
    "        \"best_counter_literal\": [],\n",
    "        \"sorting\": [],\n",
    "        \"extension\": [],\n",
    "        \"cutoff_main\": [],\n",
    "        \"cutoff\": [],\n",
    "        \"h_inc\": [],\n",
    "        \"max_restart\": [],\n",
    "        \"s_inc\": [],\n",
    "        \"pb_restarts\": [],\n",
    "        \"sp\": [],\n",
    "        \"creation date\": []\n",
    "        }\n",
    "\n",
    "for f_path in f_paths:\n",
    "    p_name = f_path.replace('data/benchmark/','')\n",
    "    data[\"creation date\"].append(os.path.getctime(f_path))\n",
    "\n",
    "    if f_path in cnf_problems:\n",
    "        data['type'].append('cnf')\n",
    "        data['p'].append([cnf_file for cnf_file in cnf_files if cnf_file in f_path][0])\n",
    "    else:\n",
    "        data['type'].append('wcnf')\n",
    "        data['p'].append([wcnf_file for wcnf_file in wcnf_files if wcnf_file in f_path][0])\n",
    "\n",
    "    with open(f_path) as f:\n",
    "        parsed_json = json.load(f)\n",
    "    if 'clauses' not in parsed_json:\n",
    "        continue\n",
    "\n",
    "    data['solver'].append('Gurobi')\n",
    "    data['ext'].append(parsed_json['parameters']['extension'])\n",
    "    data['clauses'].append(parsed_json['clauses'])\n",
    "    data['steps'].append(parsed_json['steps'])\n",
    "    tot_time = sum(parsed_json['t_hitting_set']) +sum(parsed_json['t_sat_check'])  + sum(parsed_json['t_grow'])\n",
    "    data['total time [s]'].append(tot_time)\n",
    "    data['% hs [s]'].append(round(100*sum(parsed_json['t_hitting_set'])/tot_time, 2))\n",
    "    data['% sat [s]'].append(round(100*sum(parsed_json['t_sat_check'])/tot_time,2))\n",
    "    data['% grow [s]'].append(round(100*sum(parsed_json['t_grow'])/tot_time, 2))\n",
    "    data['s_hs'].append(parsed_json['s_hs']),\n",
    "    data['s_grow'].append(parsed_json['s_grow'])\n",
    "    data['avg_s_hs'].append(round(mean(parsed_json['s_hs']), 2)),\n",
    "    data['avg_s_grow'].append(round(mean(parsed_json['s_grow']),2))\n",
    "    data['OMUS'].append(parsed_json['omus'])\n",
    "    data[\"count_clauses\"].append(parsed_json['parameters'][\"count_clauses\"] if \"count_clauses\" in parsed_json['parameters'] else None)\n",
    "    data[\"best_unit_literal\"].append(parsed_json['parameters'][\"best_unit_literal\"] if \"best_unit_literal\" in parsed_json['parameters'] else None)\n",
    "    data[\"best_counter_literal\"].append(parsed_json['parameters'][\"best_counter_literal\"] if \"best_counter_literal\" in parsed_json['parameters'] else None)\n",
    "    data[\"sorting\"].append(parsed_json['parameters'][\"sorting\"] if \"sorting\" in parsed_json['parameters'] else None)\n",
    "    data[\"extension\"].append(parsed_json['parameters'][\"extension\"] if \"extension\" in parsed_json['parameters'] else None)\n",
    "    data[\"cutoff_main\"].append(parsed_json['parameters'][\"cutoff_main\"] if \"cutoff_main\" in parsed_json['parameters'] else None)\n",
    "    data[\"cutoff\"].append(parsed_json['parameters'][\"cutoff\"] if \"cutoff\" in parsed_json['parameters'] else None)\n",
    "    data[\"h_inc\"].append(parsed_json['parameters'][\"h_inc\"] if \"h_inc\" in parsed_json['parameters'] else None)\n",
    "    data[\"max_restart\"].append(parsed_json['parameters'][\"max_restart\"] if \"max_restart\" in parsed_json['parameters'] else None)\n",
    "    data[\"s_inc\"].append(parsed_json['parameters'][\"s_inc\"] if \"s_inc\" in parsed_json['parameters'] else None)\n",
    "    data[\"pb_restarts\"].append(parsed_json['parameters'][\"pb_restarts\"] if \"pb_restarts\" in parsed_json['parameters'] else None)\n",
    "    data[\"sp\"].append(parsed_json['parameters'][\"sp\"] if \"sp\" in parsed_json['parameters'] else None)\n",
    "\n",
    "\n",
    "data[\"count_clauses\"] = [ None if val == None else next(name for name, value in vars(ClauseCounting).items() if value == int(val)) for val in data[\"count_clauses\"]]\n",
    "data[\"best_unit_literal\"]  = [ None if val == None else next(name for name, value in vars(UnitLiteral).items() if value == int(val)) for val in data[\"best_unit_literal\"]]\n",
    "data[\"best_counter_literal\"] = [ None if val == None else next(name for name, value in vars(BestLiteral).items() if value == int(val)) for val in data[\"best_counter_literal\"]]\n",
    "data[\"sorting\"] = [ None if val == None else next(name for name, value in vars(ClauseSorting).items() if value == int(val)) for val in data[\"sorting\"]]\n",
    "    \n",
    "ignored_columns = ['solver']\n",
    "\n",
    "df = pd.DataFrame (data, columns = [column for column in data if column not in ignored_columns])\n",
    "df.sort_values(['p','type','ext','clauses','OMUS',\"count_clauses\",\"best_unit_literal\",\n",
    "                \"best_counter_literal\",\"sorting\",\"extension\",\"creation date\"],\n",
    "                ascending = (True, True, True, True, True, True, True, True, True, True, False), inplace = True) \n",
    "df.drop_duplicates( ['p','type','ext','clauses','OMUS',\"count_clauses\",\"best_unit_literal\",\n",
    "                \"best_counter_literal\",\"sorting\",\"extension\",\"creation date\"], keep='First', inplace = True)\n",
    "df = df.sort_values([\"clauses\", \"steps\", \"total time [s]\"], ascending = (False, True, True))\n",
    "#qgrid_widget = qgrid.show_grid(df, show_toolbar=True)\n",
    "#qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8963136a234066b9b2dd829001a7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_omus_only = df[(df.OMUS == True)]\n",
    "#df_omus_only = df\n",
    "\n",
    "qgrid_widget = qgrid.show_grid(df_omus_only, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1391c3c2bb4fc8a30af69e8e206719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_grouped = df_omus_only.groupby('p',as_index=False)['total time [s]'].min().rename(columns={'p':'p','total time [s]' : 'min_time'})\n",
    "\n",
    "df_merged = df_grouped.merge(df_omus_only, on='p', how='right')\n",
    "df_merged = df_merged[(df_merged['total time [s]'] == df_merged['min_time'])]\n",
    "best_selected_columns = ['p',\n",
    "     'total time [s]', \n",
    "     'type', \n",
    "     'extension', \n",
    "     'clauses', \n",
    "     'steps', \n",
    "     \"count_clauses\", \n",
    "     \"best_unit_literal\", \n",
    "     \"best_counter_literal\", \n",
    "     \"sorting\"\n",
    "    ]\n",
    "df_best_only_selected_columns = df_merged[best_selected_columns]\n",
    "\n",
    "df_best_only_selected_columns.sort_values(\n",
    "    [\"clauses\", \"p\", \"total time [s]\"], \n",
    "    ascending = (False, True, True))\n",
    "qgrid_widget = qgrid.show_grid(df_best_only_selected_columns, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8602eefa7f4140efb0de95203b10a257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#new_df = old_df[((old_df['C1'] > 0) & (old_df['C1'] < 20)) & ((old_df['C2'] > 0) & (old_df['C2'] < 20)) & ((old_df['C3'] > 0) & (old_df['C3'] < 20))]\n",
    "df_selected = df[(( df['extension'] == 'greedy_param') & (df['OMUS'] == True))].sort_values(\n",
    "    [\"clauses\", \"p\", \"total time [s]\"], \n",
    "    ascending = (False, True, True))\n",
    "df_selected = df_selected[(df_selected['% hs [s]'] < 50)]\n",
    "qgrid_widget = qgrid.show_grid(df_selected, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
