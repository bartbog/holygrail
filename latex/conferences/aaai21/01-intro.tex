% !TeX root = ./main.tex

% Research

In recent research, a novel method for explaining the inferences made by constraint satisfaction solver was developed \cite{ecai/BogaertsGCG20}. 
While the techniques were developed for explaining satisfiable constraint satisfaction problems, the developed algorithms relied heavily on calls for so-called \emph{Minimal Unsatisfiable Subsets} (MUS), exploiting a one-to-one correspondence between so-called non-redundant explanations and MUSs. 
The algorithm developed by \citet{ecai/BogaertsGCG20} has two weaknesses: first of all, it provides no guarantees about the quality of the produced explanations due to internally computing $\subseteq$-minimal unsatisfiable subsets, which are often suboptimal with respect to the quality of an explanations step. Secondly, it suffers from performance problems: the lack of optimality is partly overcome by replacing a potential single call for a cost-optimal MUS by multiple calls, but this very high number of MUS calls causes that even for simple puzzles for which the unique solution can be found in a fraction of a second, the explanation generation process takes several hours. 


Motivated by these observations, we develop algorithms for MUS optimization (i.e., for computing cost-optimal MUSs) given some cost function. The algorithm we develop take inspiration from 
hitting set--based %The en-dash is on purpose! 
algorithms to compute cardinality-minimal MUSs \cite{ignatiev2015smallest} and for MAXSAT solving \cite{davies}. 

Furthermore, given the fact that a single call for generation of an explanation sequence internally employs several calls OMUS calls for each explanation step, whit all OMUS calls starting from approximately the same theory, we develop \emph{incremental} algorithms that allow reusing as many results as possible from earlier calls, so as to improve the overall runtime. 

We implemented these ideas in the cppy framework \cite{cppy}  and experimentally validate them on the puzzles of \citet{ecai/BogaertsGCG20} as well as on ... 
\todo{To be filled in later}
Our experimental results indicate that
\begin{itemize}
  \item confirm Davies's observations 
  \item show that incrementality is of crucial importance for the explanation generation task
  \item ... 
\end{itemize}
... \todo{To be filled in later} 

Summarized, the main contributions of our paper are:
\begin{itemize}
  \item We generalize the algorithm of \citet{} to allow for arbitrary \emph{monotonic} (with respect to set inclusion) optimization functions
  \item We extend by translating techniques developed for maxsat \cite{davies} and exploiting them for MUS search
  \item We develop techniques for reusing parts of the computations of an OMUS call in future OMUS calls, thereby essentially developing the first incremental OMUS solver. 
  \item We experimentally validate our algorithms in the explanation generation context of \citet{}
\end{itemize}



\ignore{
% the very many MUS calls have as a consequence that 
\emilio{Rephrase Intro: In the last few years, as AI systems employ more advanced reasoning mechanisms and computation power, it becomes increasingly difficult to understand why certain decisions are made.
Explainable (XAI), a subfield of AI, aims to fulfil the need for trustworthy AI systems to understand \emph{how} and \emph{why} the system made a decision, e.g. for verifying correctness of the system, as well as to control for biased or systematically unfair decisions.

Despite the fact that we do not (specifically) aim to explain over-constrained problems, our algorithms will also internally make use of methods to extract a minimal set of conflicting constraints often called a \emph{\underline{M}inimal \underline{U}nsatisfiable \underline{S}ubset} (MUS) or \emph{Minimal Unsatisfiable Core} \cite{marques2010minimal}.

While explainability of constraint optimisation has received little attention so far, in the related field of \textit{planning}, there is the emerging subfield of \textit{eXplainable AI planning} (XAIP)~\cite{fox2017explainable}, which is concerned with building planning systems that can explain their own behaviour.
This includes answering queries such as ``why did the system (not) make a certain decision?'', ``why is this the best decision?'', etc. In contrast to explainable machine learning research~\cite{guidotti2018survey}, in explainable planning one can make use of the explicit \textit{model-based representation} over which the reasoning happens.
Likewise, we will make use of the constraint specification available to constraint solvers, more specifically typed first-order logic~\cite{atcl/Wittocx13}.

This research fits within the general topic of Explainable Agency~\cite{langley2017explainable}, whereby in order for people to trust autonomous agents, the latter must be able to \textit{explain their decisions} and the \textit{reasoning} that produced their choices.
To provide the constraint solver with Explainable Agency~\cite{langley2017explainable}, we first formalize the problem of step-wise explaining the propagation of a constraint solver through a sequence of small inference steps.
Next, we use an optimistic estimate of a given cost function quantifying human interpretability to guide the search to \textit{simple}, low-cost, explanations thereby making use of minimal unsatisfiable subsets.
We extend this approach using \emph{reasoning by contradiction} to produce additional explanations of still difficult-to-understand inference steps.
Finally, we discuss the challenges and some outlooks to explaining how to solve constraint satisfaction problems.


\paragraph*{Publication history} This workshop paper is an extended abstract of previous papers presented at workshops and conferences \cite{claesuser,DBLP:conf/bnaic/ClaesBCGG19,ecai/BogaertsGCG20} and a journal paper under review \cite{bogaerts2020framework}.
}

\begin{enumerate}
    \item XAI
    \item MUS vs Overconstrained/Infeasibility
    \item CSP
    \item XOPT
\end{enumerate}

Contributions : 
\begin{enumerate}
    \item Efficient, greedy algorithm for explaining CSP based on OMUS 
    \item Adapatation smallest MUS adaptation to OMUS (different hs + no maxsat) 
    \item Improving OMUS algorithm from Davies' related delayed MaxSAT algorithm 
    \item Incremental OMUS computation to speed-up explanations
    \begin{itemize}
        \item hoe belangrijk is de incrementaliteit in het algorithme
        \item kunnen  we nog meer incrementeel verder gaan
    \end{itemize}
    \todo{
    \begin{itemize}
        \item Bestaande SMUS/OMUS algorihtmes incrementeel veranderen
        \begin{itemize}
            \item Bredere studie, SMUS => OMUS veralgemenen
            \item Hoe efficient zijn ze om ons probleem op te lossen
        \end{itemize}
    \end{itemize}
    }
\end{enumerate}
}

