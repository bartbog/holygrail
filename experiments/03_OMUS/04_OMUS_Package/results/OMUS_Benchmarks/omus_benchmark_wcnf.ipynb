{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import pandas as pd\n",
    "from statistics import mean, median, stdev, variance\n",
    "import qgrid\n",
    "from enum import Enum, IntEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder paths\n",
    "results_folder = 'data/benchmark/'\n",
    "cnf_path = 'data/cnf-instances/'\n",
    "wcnf_path = 'data/wcnf-instances/'\n",
    "\n",
    "\n",
    "\n",
    "# problem names\n",
    "# p = set(f_name for f_name in gurobi_ext4_files)\n",
    "f_paths = None\n",
    "\n",
    "# extension\n",
    "if os.path.exists(results_folder):\n",
    "    f_paths = [f\"{results_folder}{f}\" for f in os.listdir(results_folder) if f.endswith('.json')]\n",
    "   \n",
    "cnf_files = [f.replace('.cnf', '') for f in os.listdir(cnf_path) if f.endswith('.cnf')]\n",
    "wcnf_files = [f.replace('.wcnf', '') for f in os.listdir(wcnf_path) if f.endswith('.wcnf')]\n",
    "\n",
    "cnf_problems = [f for f in f_paths if any(cnf_file in f for cnf_file in cnf_files)]\n",
    "wcnf_problems = [f for f in f_paths if any(wcnf_file in f for wcnf_file in wcnf_files)]\n",
    "#print(f_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "keep must be either \"first\", \"last\" or False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e109c1f9e67a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 ascending = (True, True, True, True, True, True, True, True, True, True, False), inplace = True) \n\u001b[1;32m    118\u001b[0m df.drop_duplicates( ['p','type','ext','clauses','OMUS',\"count_clauses\",\"best_unit_literal\",\n\u001b[0;32m--> 119\u001b[0;31m                 \"best_counter_literal\",\"sorting\",\"extension\",\"creation date\"], keep='First', inplace = True)\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clauses\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"total time [s]\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m#qgrid_widget = qgrid.show_grid(df, show_toolbar=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   4809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4810\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4811\u001b[0;31m         \u001b[0mduplicated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   4889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4890\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_group_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxnull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduplicated_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4893\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_func_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.duplicated_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: keep must be either \"first\", \"last\" or False"
     ]
    }
   ],
   "source": [
    "class ClauseCounting(IntEnum):\n",
    "    VALIDATED = 1\n",
    "    WEIGHTS = 2\n",
    "    WEIGHTED_UNASSIGNED = 3\n",
    "\n",
    "class ClauseSorting(IntEnum):\n",
    "    IGNORE = 0\n",
    "    WEIGHTS = 1\n",
    "    UNASSIGNED = 2\n",
    "    WEIGHTED_UNASSIGNED = 3\n",
    "    LITERAL_ORDERING = 4\n",
    "\n",
    "class BestLiteral(IntEnum):\n",
    "    COUNT_PURE_ONLY = 1\n",
    "    COUNT_POLARITY = 2\n",
    "\n",
    "class UnitLiteral(IntEnum):\n",
    "    IGNORE = 0\n",
    "    RANDOM = 1\n",
    "    SINGLE_POLARITY = 2\n",
    "    POLARITY = 3\n",
    "    IMMEDIATE = 4\n",
    "\n",
    "class SatModel(IntEnum):\n",
    "    RANDOM = 1\n",
    "    BEST_CLAUSES_VALIDATED = 2\n",
    "    BEST_CLAUSE_WEIGHTS_COVERAGE = 3\n",
    "    BEST_WEIGHTED_UNASSIGNED_CLAUSE_COVERAGE = 4\n",
    "    ALL = 5\n",
    "\n",
    "\n",
    "\n",
    "data = {'p':  [],\n",
    "        'solver': [],\n",
    "        'type':[],\n",
    "        'ext' : [],\n",
    "        'clauses' : [],\n",
    "        'steps': [],\n",
    "        'total time [s]': [],\n",
    "        '% hs [s]' : [],\n",
    "        '% sat [s]' : [],\n",
    "        '% grow [s]':[],\n",
    "        's_hs':[],\n",
    "        's_grow':[],\n",
    "        'avg_s_hs':[],\n",
    "        'avg_s_grow':[],\n",
    "        'OMUS':[],\n",
    "        \"count_clauses\": [],\n",
    "        \"best_unit_literal\": [],\n",
    "        \"best_counter_literal\": [],\n",
    "        \"sorting\": [],\n",
    "        \"extension\": [],\n",
    "        \"cutoff_main\": [],\n",
    "        \"cutoff\": [],\n",
    "        \"h_inc\": [],\n",
    "        \"max_restart\": [],\n",
    "        \"s_inc\": [],\n",
    "        \"pb_restarts\": [],\n",
    "        \"sp\": [],\n",
    "        \"creation date\": []\n",
    "        }\n",
    "\n",
    "for f_path in f_paths:\n",
    "    p_name = f_path.replace('data/benchmark/','')\n",
    "    data[\"creation date\"].append(os.path.getctime(f_path))\n",
    "\n",
    "    if f_path in cnf_problems:\n",
    "        data['type'].append('cnf')\n",
    "        data['p'].append([cnf_file for cnf_file in cnf_files if cnf_file in f_path][0])\n",
    "    else:\n",
    "        data['type'].append('wcnf')\n",
    "        data['p'].append([wcnf_file for wcnf_file in wcnf_files if wcnf_file in f_path][0])\n",
    "\n",
    "    with open(f_path) as f:\n",
    "        parsed_json = json.load(f)\n",
    "    if 'clauses' not in parsed_json:\n",
    "        continue\n",
    "\n",
    "    data['solver'].append('Gurobi')\n",
    "    data['ext'].append(parsed_json['parameters']['extension'])\n",
    "    data['clauses'].append(parsed_json['clauses'])\n",
    "    data['steps'].append(parsed_json['steps'])\n",
    "    tot_time = sum(parsed_json['t_hitting_set']) +sum(parsed_json['t_sat_check'])  + sum(parsed_json['t_grow'])\n",
    "    data['total time [s]'].append(tot_time)\n",
    "    data['% hs [s]'].append(round(100*sum(parsed_json['t_hitting_set'])/tot_time, 2))\n",
    "    data['% sat [s]'].append(round(100*sum(parsed_json['t_sat_check'])/tot_time,2))\n",
    "    data['% grow [s]'].append(round(100*sum(parsed_json['t_grow'])/tot_time, 2))\n",
    "    data['s_hs'].append(parsed_json['s_hs']),\n",
    "    data['s_grow'].append(parsed_json['s_grow'])\n",
    "    data['avg_s_hs'].append(round(mean(parsed_json['s_hs']), 2)),\n",
    "    data['avg_s_grow'].append(round(mean(parsed_json['s_grow']),2))\n",
    "    data['OMUS'].append(parsed_json['omus'])\n",
    "    data[\"count_clauses\"].append(parsed_json['parameters'][\"count_clauses\"] if \"count_clauses\" in parsed_json['parameters'] else None)\n",
    "    data[\"best_unit_literal\"].append(parsed_json['parameters'][\"best_unit_literal\"] if \"best_unit_literal\" in parsed_json['parameters'] else None)\n",
    "    data[\"best_counter_literal\"].append(parsed_json['parameters'][\"best_counter_literal\"] if \"best_counter_literal\" in parsed_json['parameters'] else None)\n",
    "    data[\"sorting\"].append(parsed_json['parameters'][\"sorting\"] if \"sorting\" in parsed_json['parameters'] else None)\n",
    "    data[\"extension\"].append(parsed_json['parameters'][\"extension\"] if \"extension\" in parsed_json['parameters'] else None)\n",
    "    data[\"cutoff_main\"].append(parsed_json['parameters'][\"cutoff_main\"] if \"cutoff_main\" in parsed_json['parameters'] else None)\n",
    "    data[\"cutoff\"].append(parsed_json['parameters'][\"cutoff\"] if \"cutoff\" in parsed_json['parameters'] else None)\n",
    "    data[\"h_inc\"].append(parsed_json['parameters'][\"h_inc\"] if \"h_inc\" in parsed_json['parameters'] else None)\n",
    "    data[\"max_restart\"].append(parsed_json['parameters'][\"max_restart\"] if \"max_restart\" in parsed_json['parameters'] else None)\n",
    "    data[\"s_inc\"].append(parsed_json['parameters'][\"s_inc\"] if \"s_inc\" in parsed_json['parameters'] else None)\n",
    "    data[\"pb_restarts\"].append(parsed_json['parameters'][\"pb_restarts\"] if \"pb_restarts\" in parsed_json['parameters'] else None)\n",
    "    data[\"sp\"].append(parsed_json['parameters'][\"sp\"] if \"sp\" in parsed_json['parameters'] else None)\n",
    "\n",
    "\n",
    "data[\"count_clauses\"] = [ None if val == None else next(name for name, value in vars(ClauseCounting).items() if value == int(val)) for val in data[\"count_clauses\"]]\n",
    "data[\"best_unit_literal\"]  = [ None if val == None else next(name for name, value in vars(UnitLiteral).items() if value == int(val)) for val in data[\"best_unit_literal\"]]\n",
    "data[\"best_counter_literal\"] = [ None if val == None else next(name for name, value in vars(BestLiteral).items() if value == int(val)) for val in data[\"best_counter_literal\"]]\n",
    "data[\"sorting\"] = [ None if val == None else next(name for name, value in vars(ClauseSorting).items() if value == int(val)) for val in data[\"sorting\"]]\n",
    "    \n",
    "ignored_columns = ['solver']\n",
    "\n",
    "df = pd.DataFrame (data, columns = [column for column in data if column not in ignored_columns])\n",
    "df.sort_values(['p','type','ext','clauses','OMUS',\"count_clauses\",\"best_unit_literal\",\n",
    "                \"best_counter_literal\",\"sorting\",\"extension\",\"creation date\"],\n",
    "                ascending = (True, True, True, True, True, True, True, True, True, True, False), inplace = True) \n",
    "df.drop_duplicates( ['p','type','ext','clauses','OMUS',\"count_clauses\",\"best_unit_literal\",\n",
    "                \"best_counter_literal\",\"sorting\",\"extension\",\"creation date\"], keep='First', inplace = True)\n",
    "df = df.sort_values([\"clauses\", \"steps\", \"total time [s]\"], ascending = (False, True, True))\n",
    "#qgrid_widget = qgrid.show_grid(df, show_toolbar=True)\n",
    "#qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_omus_only = df[(df.OMUS == True)]\n",
    "#df_omus_only = df\n",
    "\n",
    "qgrid_widget = qgrid.show_grid(df_omus_only, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_omus_only.groupby('p',as_index=False)['total time [s]'].min().rename(columns={'p':'p','total time [s]' : 'min_time'})\n",
    "\n",
    "df_merged = df_grouped.merge(df_omus_only, on='p', how='right')\n",
    "df_merged = df_merged[(df_merged['total time [s]'] == df_merged['min_time'])]\n",
    "best_selected_columns = ['p',\n",
    "     'total time [s]', \n",
    "     'type', \n",
    "     'extension', \n",
    "     'clauses', \n",
    "     'steps', \n",
    "     \"count_clauses\", \n",
    "     \"best_unit_literal\", \n",
    "     \"best_counter_literal\", \n",
    "     \"sorting\"\n",
    "    ]\n",
    "df_best_only_selected_columns = df_merged[best_selected_columns]\n",
    "\n",
    "df_best_only_selected_columns.sort_values(\n",
    "    [\"clauses\", \"p\", \"total time [s]\"], \n",
    "    ascending = (False, True, True))\n",
    "qgrid_widget = qgrid.show_grid(df_best_only_selected_columns, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = old_df[((old_df['C1'] > 0) & (old_df['C1'] < 20)) & ((old_df['C2'] > 0) & (old_df['C2'] < 20)) & ((old_df['C3'] > 0) & (old_df['C3'] < 20))]\n",
    "df_selected = df[(( df['extension'] == 'greedy_param') & (df['OMUS'] == True))].sort_values(\n",
    "    [\"clauses\", \"p\", \"total time [s]\"], \n",
    "    ascending = (False, True, True))\n",
    "df_selected = df_selected[(df_selected['% hs [s]'] < 50)]\n",
    "qgrid_widget = qgrid.show_grid(df_selected, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
