% !TeX root = ./main.tex

Before presenting an algorithm that computes optimal MUSs, we first formally define the problem we are going to solve and we present an extension of the hitting set duality of \cref{prop:MCS-MUS-hittingset}. 
Throughout this section, we assume that an objective function $f: 2^\formula \to \nat$ that assigns to each subset of \formula a cost that is fixed. Our goal now is not to find arbitrary MUSs, but unsatisfiable subsets that are optimal with respect to $f$. 


% \begin{itemize}
%   \item Davies'MaxSAT version ? (takes a lot of space on paper)
%   \item OUS v1
%   \item OUS v2
% \end{itemize}
% \emilio{
%   In this section, we first introduce the notion of OUS and extend the smallest MUS approach \cite{ignatiev2015smallest} to compute optimal MUS with respect to an objective function. 
% }
% We further improve the efficiency of the OUS algorithm using ideas from the improved \textsc{MaxHS} algorithm \cite{davies2013postponing}.

\begin{definition}
  A MUS $M$ of \formula, such that no MUS $M'$ exists with $f(M')<f(M)$, is called an \emph{$f$-Optimal Unsatisfiable Subset} (f-OUS) of \formula.
\end{definition}

\begin{definition}
  Let $\m{H}$ be a collection of subsets of a set $S$ and $c$ a function $2^S\to\nat$. 
  A hitting set of $\m{H}$ is called \emph{$c$-optimal} if there are no hitting sets $h'$ of $\m{H}$ with $c(h')<c(h)$. 
\end{definition}
In case our collection of sets $\m{H}$ happen to be subsets of \formula, we can use the function $f$ to measure the costs. 
% 
% While any objective function is applicable for OUSes, the set of possible objective functions is constrained to \emph{monotonic} functions to guarantee that the algorithm \ref{alg:omus} presented below finds the OUS.

% \begin{definition}
%   Given a CNF Formula \formula, let $f : 2^{\formula} \rightarrow \mathbb{R}$ be a mapping of a sets of clauses to real numbers. f is said to be a \emph{monotonic} objective function if for any subsets $\m{A}$, $\m{B}$ of \formula if $\m{A} \subseteq \m{B}$ then $f(\m{A}) \leq f(\m{B})$.
% \end{definition}

The hitting set duality now straightforwardly generalizes as follows. 

\begin{proposition}\label{prop:optimal-hitting-set}
  A set $\m{U} \subseteq \formula$ is an $f$-OUS of \formula iff $\m{U}$ is an $f$-optimal hitting set of \mcses{\formula}.
\end{proposition}
\tias{and inversely? now it is not a duality... perhaps 'the duality allows us to derive the following:'} \bart{The inverse also holds. We can add it (might indeed make more sense), though we only use one direction)}

In order to find an OUS, there is no need to explicitly enumerate all MCSes of \formula. In practice it suffices to compute sufficiently many of them. \tias{missing argument of why being optimal and unsat is sufficient to be the f-ous... because the hs is also a (superset) of a smaller H, an OUS always has to be unsatisfiable, and so any HS of H subset MCS is either SAT or the OUS?}\bart{I added a proof}
% and the correction subsets considered need not neccesarily be maximal. 
The following proposition formalizes this. 
% 
% Lemma \ref{lemma:K} specifies that, in practice, it is not required to enumerate all MCSes of \formula.
% The algorithm only requires finding an optimal hitting set on \mcses{\formula} tat is unsatisfiable.

\begin{proposition}\label{prop:K}
  Let $\m{H}$ be a set of correction subsets of \formula \tias{should be subset of correction subsets $H \subseteq mcss$?} \bart{the way it is phrased now also allows for non-minimal correction sets. Which is needed if grow is nonoptimal}. 
  If $\m{U}$ is an $f$-optimal hitting set of \m{H} and $\m{U}$ is unsatisfiable, then $\m{U}$ is an $f$-OUS of \formula. 
\end{proposition}
\begin{proof}
%   We know that . 
  All that is left to show is $f$-optimality of $\m{U}$.
  If some other unsatisfiable subset $\m{U}'$ exists with $f(\m{U}')\leq f(\m{U})$, we know that $\mu{U}'$ would hit every minimal correction set of \m{F}, and hence also every set in \m{H} (since every correction is the superset of a minimal correction set).
  Since $\m{U}$ is an $f$-optimal hitting and $\m{U}'$ also hits $\m{H}$, it must thus be that $f(\m{U})=f(\m{U'})$. 
%   
\end{proof}


% \begin{proposition}
%   If $\m{U}$ is an $f$-OUS of \formula and $\m{C}$ a correction subset of \formula, then 
% \end{proposition}


We are now ready to present our basic OUS algorithm in \cref{alg:omus}. 
The algorithm keeps track of a set $\m{H}$ of (minimal) correction subsets of $\formula$. 
It makes use of a procedure \ohs that computes an optimal (with respect to $f$) hitting set $\formula'$  of a given set of subsets of \formula.
We take inspiration for the hitting set approach to solving partial weighted MaxSAT~\cite{davies2011solving} and will use a MIP solver to compute the optimal hitting set.
Whenever such a hitting set is found, a \sat-call checks whether the result is satisfiable. If it is, \cref{prop:K} guarantees that the result is an OUS. 
If it is not, we know that the hitting set is a satisfiable subset. We now need to compute and add an MCS which is not hit by the found hitting set.
As is common, we first use a procedure \grow to extend the hitting set to a set $\formula''$ with $\formula'\subseteq \formula''\subseteq\formula$ such that $\formula''$ is still satisfiable. By definition $\formula \setminus \formula''$ is a correction subset; we add this complement to $\m{H}$ \bart{better sentence}. \tias{smth about MSS/MCS, although the way we explain it it needs not be 'maximal', should we also be explicit about that? I don't like the current version.} \bart{For our algorithms, it is crucial that they don't have to be maximal. Otherwise all approximations such as greedy grows would be incorrect}

The implementation of \grow can be achieved in different ways.
In fact, we could call a weighted partial \textsc{MaxSAT} solver to find the maximal satisfiable subset of clauses grown from the hitting set.
In practice, we use a greedy approximative method to find a sastisfying assignment favoring literals that will satisfy the most clauses of highest weights.
More precisely, we rank the clauses based on the ratio of weight to the number of literals not yet assigned in the clause.
\tias{we doen weighted partial maxsat, waarbij we de satisfying solution van de SAT call gebruiken. Details hiervan leiden af van de paper imho, en we hebben geen tijd om te experimenteren wat best is. Mss gewoon:}
... In practice, we use the model found by the SAT call on line 4 and let a maxsat solver extend it to maximally cover $\formula$. We note that typically most literals are part of the found model of $\formula'$ and so this maxsat problem is considerably smaller than $\formula$.
\bart{Akkoord. Na de paper deadline wil ik wel eens weten welke weights we gebruiken...}

\todo{beter uitleggen. Nog niet zo duidelijk. Ook niet zeker of dit op deze moment echt van belang is.}
\bart{OOK: hoe gebruiken we de maxsat solver, zoeken we een MSS met een zo HOOG mogelijke kost? Is dat ``optimaal'' in zekere zin? Ik weet het eigenlijk niet... Een MSS met hoge kost, betekent dat de MCS een lage kost heeft. Maar een MCS met een hoge kost is eigenlijk informatiever, neen? Dat geeft een strengere constraint op onze hitting sets? 
Wel... We willen zo weinig mogelijk constraints in de MCS (om een sterke cosntratint op de hitting set te krijgen), maar we hebben voor die zaken wel liefst GROTE gewichten in de MCS. 
Dus... eerlijk... ik weet niet zo goed of we gewichten hier wel in rekening moeten brengen... En tenzij we het zelf volledig snappen zou ik het niet in de paper schrijven :-)}


% 
% This can be implemented in various ways, e.g., using a MAXsat call can guarantee that $\formula''$ is an MSS of \formula. Another possibility is  -- given a model $I$ of $\formula''$ -- to take $\formula''$ to be $\{c\in\formula \mid I\models c\}$.

% \newcommand\setstohit{\ensuremath{\m{H} }\xspace}
\begin{algorithm}[ht]
  \DontPrintSemicolon
  $\setstohit  \gets \emptyset$ \; %\label{omus-line1} 
  \While{true}{
    $\F' \gets \ohs(\setstohit,f) $ \label{smus-hs} \;%\tcp*{\small Find \textb    $\setstohit  \gets \setstohit  \cup \{  \formula \setminus \F''\}$ \;
% f{optimal} solution}
    % \tcp{\small set with all unique clauses from hitting set}
%     (sat?, $\kappa$) $\gets$ \texttt{SatSolver}($hs$)\;
    % \tcp{If SAT, $\kappa$ contains the satisfying truth assignment}
    % \tcp{IF UNSAT, $hs$ is the OUS }
    \If{ $\lnot \sat(\F')$}{
      \Return{$\F'$} \;
    }
    $\F'' \gets  \grow(\F',\F) $\;
    $\setstohit  \gets \setstohit  \cup \{  \formula \setminus \F''\}$ \;
  }
  \caption{$\omus(\formula,f)$ }
  \label{alg:omus}
\end{algorithm}
\tias{I would add the 'delayed' extension here...}
\bart{Depends on what our core contribution is. I like moving contributions as much to the front of the paper as possible.... }

% 
% \begin{algorithm}[ht]
%   \DontPrintSemicolon
%   $\m{K} \gets \emptyset$  \label{omus-line1} \;
%   \While{true}{
%     $hs \gets$ \texttt{FindMinCostHittingSet}($\m{K}, f$) \label{omus-hs} \;%\tcp*{\small Find \textbf{optimal} solution}
%     % \tcp{\small set with all unique clauses from hitting set}
%     (sat?, $\kappa$) $\gets$ \texttt{SatSolver}($hs$)\;
%     % \tcp{If SAT, $\kappa$ contains the satisfying truth assignment}
%     % \tcp{IF UNSAT, $hs$ is the OUS }
%     \If{ not sat?}{
%       \Return{$(hs,  \m{K})$} \;
%     }
%     $MSS \gets  \texttt{Grow}($hs$) $\;
%     $\m{K} \gets \m{K} \cup \{  \formula$ $\setminus MSS\}$ \;
%   }
%   \caption{\textsc{OUS($\formula, \ f$)}}
%   \label{alg:omus}
% \end{algorithm}


% The \texttt{OUS} algorithm repeatedly computes the optimal hitting set $hs$ (line \ref{omus-hs}) on the already found $\m{K}$, the MCSes of \formula. If the $hs$ is satisfiable, $hs$ is grown grown to 
% The algorithm terminates and $hs$ is guaranteed to be the OUS based on lemma \ref{lemma:K}. 

% From proposition \ref{prop:MCS-MUS-hittingset}, if $hs$ is unsatisfiable, that means it hits all \mcses{\formula}. 
% Furthermore, $hs$ is also a cost optimal hitting set on $\m{K}$. It means that if we add any MCS to $\m{K}$, the cost of other hitting sets will either increase in cost or remain the same.

% Lemma \ref{lemma:K} also 

% Note if we assign a weight to all clauses equal to the number of literals it contains, then we reduce the problem of finding an optimal hitting set back to finding the minimum hitting set.
% % The algorithm then computes the smallest MUS instead of the OUS \cite{ignatiev2015smallest}.
% 
% % \subsection*{Implementation}
% 
% Inspired by the approach of Davies and Bacchus \cite{davies2011solving}, the optimal hitting set problem is formulated as a Linear integer Program and encoded into the MIP solver. 
% Contrary to the \texttt{SMUS} algorithm, which uses the \textsc{SAT} solver to compute minimum hitting sets. 

% The implementation of the grow procedure can be achieved in different ways.
% In fact, we could call a weighted partial \textsc{MaxSAT} solver to find the maximal satisfiable subset of clauses grown from the hitting set.
% In practice, we use a greedy approximation strategy to find a sastisfying assignment favoring literals that will satisfy the most clauses of highest weights.
% More precisely, we rank the clauses based on the ratio of weight to the number of literals not yet assigned in the clause.
% 



% \begin{algorithm*}
%   \DontPrintSemicolon
%   \SetKwSwitch{Switchy}{Case}{Default}{swtich}{}{case}{otherwhise}{}%
%   \Begin{
%     \tcp{F = unsatisfiable CNF formula; M = Collection of MSSes; $f_{cost}$ = cost function}

%     $\m{K} \gets $ $\emptyset$ \;
%     \tcp{grow mss from input mss}
%     \ForEach(){$\m{MSS} \in \m{M}$}{
%       $\m{MSS}' \gets$ {Grow($\formula \cap \m{MSS}$)} \;
%       % $\m{MSS} \gets $  \;
%       $\m{K} \gets \m{K} \cup \{  \formula \setminus \m{MSS}'\}$ \;
%     }

%     % $\m{M} \gets \emptyset$ \;
%     mode $\gets$ mode\_greedy \;
%     % \sout{$\m{H} \gets \m{H}_0$} \;
%     \While{true}{
%       % \tcp{Find a series of non-optimal solutions}
%       \While{true \label{alg:omus-nonOPT-nested-start}}{
%         \Switch{$nonOptLevel$}{
%           \Case{mode\_incr}{
%             $hs \gets$ {FindIncrementalHittingSet}($\m{K}$, $\m{C}$, $hs$)\;
%           }
%           \Case{mode\_greedy}{
%             $hs \gets$ {FindGreedyHittingSet}($\m{K}$)\;
%           }
%         }

%         (sat?, $\kappa$) $\gets$ {SatSolver}($hs$)\;
%         \uIf{ not sat?}{
%           \Switch{$nonOptLevel$}{
%             \Case{mode\_incr}{
%               mode $\gets$  mode\_greedy \;
%             }
%             \Case{mode\_greedy}{
%               mode $\gets$  mode\_opt \;
%               \textbf{break} \;
%             }
%           }
%         }
%         \uElse{
%           % \todo{is this really correct to add it to MSS ? }\;
%           $MSS \gets $ {Grow}($hs$) \;
%           $\m{M} \gets \m{M} \cup \{  MSS \}$ \;
%           $\m{K} \gets \m{K} \cup \{  \formula \setminus MSS\}$ \;
%           mode $\gets$  mode\_incr \;
%         }
%       }
%       $hs \gets$ {OptimalHittingSet}($\m{K}, f_{cost}$) \;

%       (sat?, $\kappa$) $\gets$ {SatSolver}($hs$)\;

%       \If{ not sat?}{
%         \Return{$hs$,  $\m{M}$}
%       }
%       $MSS \gets $ {Grow}($hs$) \;
%       $\m{M} \gets \m{M} \cup \{  MSS \} $\;
%       $\m{K} \gets \m{K} \cup \{  \formula \setminus MSS\}$ \;
%       mode $\gets$ mode\_incr \;
%       \label{alg:omus-nonOPT-nested-end}
%     }
%   }
%   \caption{OUS-Delayed($\formula, \m{M}, f_{cost}$)}
%   \label{alg:omus-nonOPT}
% \end{algorithm*}

