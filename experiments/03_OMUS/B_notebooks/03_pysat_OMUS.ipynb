{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "# pysat library\n",
    "from pysat.solvers import Solver, SolverNames\n",
    "from pysat.formula import CNF, WCNF\n",
    "from pysat.examples.fm import FM\n",
    "from pysat.examples.musx import MUSX\n",
    "\n",
    "# or-tools library\n",
    "from ortools.linear_solver import pywraplp\n",
    "\n",
    "# numpy\n",
    "#import numpy as np\n",
    "\n",
    "# configs\n",
    "import pprint\n",
    "\n",
    "# utilities\n",
    "ppprint = pprint.PrettyPrinter(indent=4).pprint\n",
    "def debug(info, verbose=True):\n",
    "    if verbose:\n",
    "        print(info)\n",
    "\n",
    "def debug_ppprint(info, verbose=False):\n",
    "    if verbose:\n",
    "        print(json.dumps(info, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pysat pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderPaths={\n",
    "    'easyInstances':'/home/crunchmonster/Documents/VUB/02_Research/02_Notes/02_OMUS/B_data/easy_instances/',\n",
    "    'instance':'/home/crunchmonster/Documents/VUB/02_Research/02_Notes/02_OMUS/B_data/instance/',\n",
    "    'aaaiInstances':'/home/crunchmonster/Documents/VUB/02_Research/02_Notes/02_OMUS/B_data/hard_instances/aaai_instances',\n",
    "    'isingModel':'/home/crunchmonster/Documents/VUB/02_Research/02_Notes/02_OMUS/B_data/hard_instances/Generalized_Ising_model',\n",
    "    'maxSat':'/home/crunchmonster/Documents/VUB/02_Research/02_Notes/02_OMUS/B_data/hard_instances/maxsat_staffscheduling_instances',\n",
    "    'circuitDebugging':'/home/crunchmonster/Documents/VUB/02_Research/02_Notes/02_OMUS/B_data/hard_instances/ms_industrial/circuit-debugging-problems',\n",
    "    'safarpour':'/home/crunchmonster/Documents/VUB/02_Research/02_Notes/02_OMUS/B_data/hard_instances/ms_industrial/sean-safarpour'\n",
    "}\n",
    "\n",
    "class Difficulty(Enum):\n",
    "    EASY = 1\n",
    "    MEDIUM = 2\n",
    "    HARD = 3\n",
    "    ALL = 0\n",
    "\n",
    "def instanceDiff(fileSize):\n",
    "    \n",
    "    mb = 10* 1024 ** 1\n",
    "    mediumUb = 10 * mb\n",
    "    if fileSize < mb:\n",
    "        return Difficulty.EASY\n",
    "    elif fileSize < mediumUb:\n",
    "        return Difficulty.MEDIUM\n",
    "    else:\n",
    "        return Difficulty.HARD\n",
    "\n",
    "    \n",
    "def allInstances(difficulty, cnfExtensions=['.cnf', '.wcnf']):\n",
    "    instances = []\n",
    "    for folder in folderPaths:\n",
    "        instanceFolder = Path(folderPaths[folder])\n",
    "        instances += [x for x in instanceFolder.iterdir() if x.is_file() and x.suffix in cnfExtensions]\n",
    "    \n",
    "    if difficulty is Difficulty.ALL:\n",
    "        return instances\n",
    "\n",
    "    sizeFilteredInstances = list(filter(lambda x: instanceDiff(x.stat().st_size) is difficulty, instances))\n",
    "\n",
    "    return sizeFilteredInstances\n",
    "    \n",
    "def getDataPaths(cnfExtensions=['.cnf', '.wcnf'], difficulty= Difficulty.EASY):\n",
    "    \n",
    "    if difficulty not in Difficulty:\n",
    "        ppprint('Difficulty must be in ' +str(difficulties) + ' defaulting to easy.')\n",
    "        difficulty = Difficulty.EASY\n",
    "    \n",
    "    instances = allInstances(difficulty, cnfExtensions)\n",
    "\n",
    "    return instances\n",
    "\n",
    "def cnfInstances(difficulty=Difficulty.EASY):\n",
    "    instances = [instance for instance in getDataPaths(cnfExtensions=['.cnf'], difficulty= difficulty)] \n",
    "    return instances\n",
    "\n",
    "def wcnfInstances(difficulty=Difficulty.EASY):\n",
    "    instances = [instance for instance in getDataPaths(cnfExtensions=['.wcnf'], difficulty= difficulty)] \n",
    "    return instances\n",
    "\n",
    "def CNFisUnsat(instance, verbose=True):\n",
    "    with Solver() as s:\n",
    "        cnf = CNF(from_file=instance)\n",
    "        added = s.append_formula(cnf.clauses, no_return=False)\n",
    "        solved = s.solve()\n",
    "    return solved\n",
    "\n",
    "def WCNFisUnsat(instance, verbose=True):\n",
    "    with Solver(name = SolverNames.minisat22[0]) as s:\n",
    "        wcnf = WCNF(from_file=instance)\n",
    "        added = s.append_formula(wcnf.clauses, no_return=False)\n",
    "        solved = s.solve()\n",
    "    return solved\n",
    "\n",
    "def cnfUnsatInstances():\n",
    "    return [instance  for instance in cnfInstances() if CNFisUnsat(instance)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test extensions on simple cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_flatten_set():\n",
    "    print(\"Testing flatten set\")\n",
    "    assert sorted(flatten_set([[1, 2, 3],[4, 1 ,3]])) == [1,2,3, 4], \"Should be 6\"\n",
    "\n",
    "def test_extension1():\n",
    "    input_cnf_clauses = [\n",
    "        [1],\n",
    "        [2, 3, 5],\n",
    "        [3, 6, 7],\n",
    "        [-4, -1],\n",
    "        [-4],\n",
    "        [-4, -8]\n",
    "    ]\n",
    "    input_F_prime = {0, 4}\n",
    "    \n",
    "    output_F_prime = {0, 3, 4, 5}\n",
    "    \n",
    "    ext1_F_prime = extension1(input_cnf_clauses, input_F_prime)\n",
    "    \n",
    "    assert sorted(output_F_prime) == sorted(ext1_F_prime), \"Should be equal\"\n",
    "\n",
    "def test_extension2():\n",
    "    input_cnf_clauses = [\n",
    "        [1],\n",
    "        [2, 3, 5],\n",
    "        [3, 6, 7, -8],\n",
    "        [-4, -1],\n",
    "        [-4],\n",
    "        [-4, -8]\n",
    "    ]\n",
    "    input_F_prime = {0, 4}\n",
    "    \n",
    "    expected_output = {0, 2, 3, 4, 5}\n",
    "    \n",
    "    ext1_F_prime = extension2(input_cnf_clauses, input_F_prime)\n",
    "    \n",
    "    assert sorted(expected_output) == sorted(ext1_F_prime), f\"{ext1_F_prime} == {expected_output}\"\n",
    "    \n",
    "def run_tests():\n",
    "    test_flatten_set()\n",
    "    test_extension1()\n",
    "    test_extension2()\n",
    "    print(\"Everything passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_omus(H, h, F_prime, C, weights, clauses, write_file=True):\n",
    "    d = {\n",
    "        'H':H,\n",
    "        'h':h,\n",
    "        'F_prime':F_prime,\n",
    "        'C':C, \n",
    "        #'weights': weights,\n",
    "        #'clauses': clauses\n",
    "    }\n",
    "    \n",
    "    ppprint(d)\n",
    "\n",
    "def complement(F, F_prime):\n",
    "    return set([i for i in range(len(F))]) - set(F_prime)\n",
    "\n",
    "# def unique_clauses_hs(H):\n",
    "#    return flatten_set(H)\n",
    "\n",
    "def flatten_set(H):\n",
    "    return set([val for sublist in H for val in sublist])\n",
    "\n",
    "def f(x):\n",
    "    # weighted based on the number of literals inside the clause\n",
    "    # return 1\n",
    "    return len(x)\n",
    "\n",
    "def cnf_weights(cnf, weight = f):\n",
    "    return [weight(clause) for clause in cnf.clauses]\n",
    "\n",
    "def clauses_weights(clauses, weight = f):\n",
    "    return [weight(clause) for clause in clauses]\n",
    "\n",
    "   \n",
    "def create_data_model(H, weights):\n",
    "    \"\"\"Stores the data for the problem.\"\"\"\n",
    "    \n",
    "    # indices of clauses used\n",
    "    indices_H = sorted(flatten_set(H))\n",
    "    \n",
    "    n_vars_H = len(indices_H)\n",
    "    n_constraints = len(H)\n",
    "    \n",
    "    data = {}\n",
    "    data['indices'] = indices_H\n",
    "    data['num_constraints'] = n_constraints\n",
    "    data['bounds'] = [1] * n_constraints\n",
    "    data['num_vars'] = n_vars_H \n",
    "    data['obj_coeffs'] = {index:weights[index] for index in indices_H}\n",
    "\n",
    "    # constraint coefficients hij = 1 if variable x_j is in set h_i\n",
    "    constraint_coeffs = [[0 for _ in range(n_vars_H)] for _ in range(n_constraints)] \n",
    "\n",
    "    for j in range(n_constraints):\n",
    "        hj = H[j]\n",
    "        for i in range(n_vars_H):\n",
    "            if indices_H[i] in hj:\n",
    "                constraint_coeffs[j][i] = 1\n",
    "\n",
    "    data['constraint_coefficients'] = constraint_coeffs\n",
    "    \n",
    "    # matching clause indices with position in list of clause indices \n",
    "    # ex: {3 : 0, 7: 1, ....} clause 3 position 0, clause 7 position 1, ...\n",
    "    data['matching_table'] = {idx : i for i, idx in enumerate(indices_H) }\n",
    "    return data\n",
    "\n",
    "def checkSatClauses(clauses, F_prime):\n",
    "    c = [clauses[i] for i in F_prime]\n",
    "    with Solver() as s:\n",
    "        added = s.append_formula(c, no_return=False)\n",
    "        solved = s.solve()\n",
    "    return solved    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smus_CNF():\n",
    "    l = 1\n",
    "    m = 2\n",
    "    n = 3\n",
    "    p = 4\n",
    "    s = 5\n",
    "    t = 6\n",
    "    cnf = CNF()\n",
    "    cnf.append([-s])    # c1: ¬s\n",
    "    cnf.append([s, -p]) # c2: s or ¬p\n",
    "    cnf.append([p])     # c3: p\n",
    "    cnf.append([-p, m]) # c4: ¬p or m\n",
    "    cnf.append([-m, n]) # c5: ¬m or n\n",
    "    cnf.append([-n])    # c6: ¬n\n",
    "    cnf.append([-m, l]) # c7 ¬m or l\n",
    "    cnf.append([-l])    # c8 ¬l\n",
    "    return cnf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Hitting set MIP implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimalHittingSet(H, weights):\n",
    "    data = create_data_model(H, weights)\n",
    "    # [START solver]\n",
    "    # Create the mip solver with the CBC backend.\n",
    "    solver = pywraplp.Solver('OptimalHittingSet', \n",
    "                             pywraplp.Solver.BOP_INTEGER_PROGRAMMING)\n",
    "    # [END solver]\n",
    "    \n",
    "    # [START variables]\n",
    "    #infinity = solver.infinity()\n",
    "    x = {}\n",
    "    for j in data['indices']:\n",
    "        x[j] = solver.BoolVar('x[%i]' % j)\n",
    "    # [END variables]\n",
    "    \n",
    "    # [START constraints]\n",
    "    for i in range(data['num_constraints']):\n",
    "        # for all i in {1.. |H|}: sum x[j] * hij >= 1\n",
    "        constraint_expr = [data['constraint_coefficients'][i][j] * x[idx] for j, idx in enumerate(data['indices'])]\n",
    "        solver.Add(sum(constraint_expr) >= data['bounds'][i])\n",
    "    # [END constraints]\n",
    "    \n",
    "    # [START objective]\n",
    "    # Maximize sum w[i] * x[i]\n",
    "    objective = solver.Objective()\n",
    "    for idx in data['indices']:\n",
    "        objective.SetCoefficient(x[idx], data['obj_coeffs'][idx])\n",
    "    objective.SetMinimization()\n",
    "    # [END objective]\n",
    "    \n",
    "    # Solve the problem and print the solution.\n",
    "    # [START print_solution]\n",
    "    status = solver.Solve()\n",
    "\n",
    "    if status == pywraplp.Solver.OPTIMAL:\n",
    "        #print('Objective value =', solver.Objective().Value())\n",
    "        return [x[j].solution_value() for j in data['indices']]\n",
    "    else:\n",
    "        print('The problem does not have an optimal solution.', status)\n",
    "        return []\n",
    "    # [END print_solution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validated literals: {-8, 1, -4}\n",
      "{   'cnf_clauses': [   [1],\n",
      "                       [2, 3, 5],\n",
      "                       [3, 6, 7, -8],\n",
      "                       [3, 6],\n",
      "                       [5, 9],\n",
      "                       [2, -7],\n",
      "                       [-4, -1],\n",
      "                       [-4],\n",
      "                       [-4, -8]],\n",
      "    'ext2_F_prime': {0, 2, 6, 7, 8},\n",
      "    'new_F_prime': {0, 7}}\n",
      "validated literals: {-8, 1, -4}\n",
      "{   'cnf_clauses': [   [1],\n",
      "                       [2, 3, 5],\n",
      "                       [3, 6, 7, -8],\n",
      "                       [3, 6],\n",
      "                       [5, 9],\n",
      "                       [2, -7],\n",
      "                       [-4, -1],\n",
      "                       [-4],\n",
      "                       [-4, -8]],\n",
      "    'ext2_F_prime': {0, 2, 6, 7, 8},\n",
      "    'new_F_prime': {0, 2, 6, 7, 8}}\n"
     ]
    }
   ],
   "source": [
    "def checkConflict(literals):\n",
    "    for l in literals:\n",
    "        assert -l not in literals, f\"conflicting literals are present {l}, {-l}\"\n",
    "\n",
    "def default_extension(cnf_clauses, F_prime):\n",
    "    return F_prime\n",
    "\n",
    "def extension1(cnf_clauses, F_prime):\n",
    "    \"\"\"\n",
    "    \n",
    "        Add all clauses that are true based on the assignment by the model of Fprime\n",
    "        :param cnf_clauses: a collection of clauses (list of literals).\n",
    "        :param F_prime: hitting set : a list of clauses.\n",
    "        \n",
    "        :type cnf_clauses: iterable(iterable(int))\n",
    "        :type F_prime: iterable(int)    \n",
    "        \n",
    "    \"\"\"\n",
    "    # new set of validated literals\n",
    "    new_F_prime = set(F_prime)\n",
    "    \n",
    "    # all literals (clauses with 1 element) validated in current hitting set\n",
    "    validated_literals = {cnf_clauses[index][0] for index in new_F_prime if len(cnf_clauses[index]) == 1}\n",
    "    \n",
    "    # remaining clauses to check for validation\n",
    "    remaining_clauses = {i for i in range(len(cnf_clauses))} - F_prime\n",
    "    \n",
    "    for c in remaining_clauses:\n",
    "        clause = cnf_clauses[c]\n",
    "        for literal in validated_literals:\n",
    "            if literal in clause:\n",
    "                new_F_prime.add(c)\n",
    "\n",
    "    #validated_variables = flatten_set(validated_clauses)\n",
    "    return new_F_prime\n",
    "\n",
    "def find_best_literal(clauses, remaining_clauses, conflictual_literals):\n",
    "    literal_validatable_clauses = {l : 0 for l in conflictual_literals}\n",
    "    \n",
    "    validatable_clauses = {}\n",
    "    for c in remaining_clauses:\n",
    "        clause = clauses[c]\n",
    "        \n",
    "        for literal in clause:\n",
    "            if literal in conflictual_literals:\n",
    "                validatable_clauses.add(c)\n",
    "    \n",
    "    for c in validatable_clauses:\n",
    "        clause = clauses[c]\n",
    "        for literal in clause:\n",
    "            if literal in conflictual_literals:\n",
    "                literal_validatable_clauses[literal] += 1\n",
    "    \n",
    "    # https://stackoverflow.com/questions/268272/getting-key-with-maximum-value-in-dictionary\n",
    "    best_literal = max(literal_validatable_clauses.iterkeys(), key=(lambda key: literal_validatable_clauses[key]))\n",
    "    return best_literal\n",
    "    \n",
    "def extension2(cnf_clauses, F_prime, random_assignment = True):\n",
    "    \"\"\"\n",
    "    \n",
    "            Step 1 : Compute clauses with unique literals\n",
    "            \n",
    "            Step 2 :\n",
    "                2.1 Compute validated clauses\n",
    "                2.2 Compute remaining clauses\n",
    "            \n",
    "            Step 3:\n",
    "                3.1 Compute all literal in validated clauses\n",
    "                3.2 remove already validated literals from unique literal clauses\n",
    "                3.3 remove negation of already validated literals from unique clauses\n",
    "            \n",
    "            Step 4:\n",
    "                4.1 Seperate all remaining literals in validated clauses in 2 parts:\n",
    "                    4.1.1 literals without negation of literal present\n",
    "                    4.1.2. literals with negation present\n",
    "            \n",
    "            Step 5: Add all remaining clauses validated by assignement literals w/o negation\n",
    "            \n",
    "            Step 6:\n",
    "                6.1a choose first literal from all literals with negation\n",
    "                                or\n",
    "                6.1b choose literal with best clause propagation\n",
    "                6.2 Add all remaining clauses validated by assignement of literal                 \n",
    "                \n",
    "    \"\"\"\n",
    "    # TODO: \n",
    "    # - add while loop to propagate as long as possible as long as possible\n",
    "    #   whenever len(other_literals ) > 0 \n",
    "    # \n",
    "    # - exploit validatable clauses\n",
    "    \n",
    "    new_F_prime = set(F_prime)\n",
    "\n",
    "    # Step 1 : clauses with unique literals\n",
    "    # clauses with 1 literal \n",
    "    unique_literal_validated_clauses = {index for index in new_F_prime if len(cnf_clauses[index]) == 1}\n",
    "    \n",
    "    # literals validated in clauses with 1 literal\n",
    "    validated_literals = {cnf_clauses[index][0] for index in unique_literal_validated_clauses}\n",
    "    \n",
    "    # non-unique clauses\n",
    "    remaining_clauses = {i for i in range(len(cnf_clauses))} - unique_literal_validated_clauses\n",
    "    \n",
    "    # Step 2 : clauses with unique literals\n",
    "    # all clauses satisfied by current single literal assignments of Fprime\n",
    "    satisfied_clauses = set()\n",
    "    \n",
    "    # for every literal in validated literal check for any clause satisfied \n",
    "    for literal in validated_literals:\n",
    "        for c in remaining_clauses:\n",
    "            clause = cnf_clauses[c]\n",
    "            if literal in clause:\n",
    "                satisfied_clauses.add(c)\n",
    "                new_F_prime.add(c)\n",
    "    \n",
    "    # remove unique literal clauses already validated\n",
    "    satisfied_clauses -= unique_literal_validated_clauses\n",
    "\n",
    "    remaining_clauses -= satisfied_clauses\n",
    "    \n",
    "    # remaining validated clauses in F prime\n",
    "    assert all([True if -i not in validated_literals else False for i in validated_literals]), \"literal conflict\"\n",
    "        \n",
    "    # remaining literals to assign\n",
    "    other_literals = flatten_set([cnf_clauses[index] for index in satisfied_clauses])\n",
    "\n",
    "    # remove already validated literals\n",
    "    other_literals -= validated_literals\n",
    "    \n",
    "    # remove negated already validated literals\n",
    "    other_literals -= {-i for i in validated_literals}\n",
    "    \n",
    "    # filtered literals with negated literal also present \n",
    "    conflict_free_literals = {i for i in other_literals if -i not in other_literals}\n",
    "    \n",
    "    # remove all clauses validated by conflict free literals\n",
    "    for literal in conflict_free_literals:\n",
    "        clauses_to_remove = set()\n",
    "        for c in remaining_clauses:\n",
    "            clause = cnf_clauses[c]\n",
    "            if literal in clause:\n",
    "                clauses_to_remove.add(c)\n",
    "                new_F_prime.add(c)\n",
    "        remaining_clauses -= clauses_to_remove\n",
    "\n",
    "    validated_literals |= conflict_free_literals\n",
    "\n",
    "    other_literals -= conflict_free_literals\n",
    "    # remaining conflictual literals to validate\n",
    "    conflictual_literals = set(other_literals)    \n",
    "   \n",
    "    # check if only conflictual literals are present in conflictual literals\n",
    "    assert all([True if -i in conflictual_literals else False for i in conflictual_literals]), \"conflictual literals error\"\n",
    "    assert len(conflictual_literals) % 2 == 0, \"check remaining literals are present in pairs\"\n",
    "    \n",
    "    # for every literal, remove its negation and \n",
    "    while len(conflictual_literals) > 0:\n",
    "        # randomly assigns truthness value\n",
    "        if random_assignment:\n",
    "            literal = conflictual_literals[0]\n",
    "        else: \n",
    "            literal = find_best_literal(clauses, remaining_clauses, conflictual_literals)\n",
    "            \n",
    "        # SANITY CHECK : add to validated literals\n",
    "        assert literal not in validated_literals, \"literal already present\"\n",
    "        assert -literal not in validated_literals, \"negation of literal already present, conflict !!!\"\n",
    "        validated_literals.add(literal)\n",
    "\n",
    "        # remove literal and its negation\n",
    "        conflictual_literals.remove(literal)\n",
    "        conflictual_literals.remove(-literal)\n",
    "\n",
    "        # remove validated clauses\n",
    "        clauses_to_remove = set()\n",
    "        \n",
    "        for c in remaining_clauses:\n",
    "            clause = cnf_clauses[c]\n",
    "            if literal in clause:\n",
    "                clauses_to_remove.add(c)\n",
    "                new_F_prime.add(c)\n",
    "        remaining_clauses -= clauses_to_remove\n",
    "    print(\"validated literals:\", validated_literals)   \n",
    "    return new_F_prime\n",
    "\n",
    "def extension2silly(cnf_clauses, F_prime, random_assignment = True):\n",
    "    \"\"\"\n",
    "    \n",
    "            Repeatedly apply extension 2 until there is no more progress\n",
    "            Propagate as much as possible\n",
    "                \n",
    "    \"\"\"\n",
    "    # TODO: \n",
    "    # - add while loop to propagate as long as possible as long as possible\n",
    "    #   whenever len(other_literals ) > 0 \n",
    "    # \n",
    "    # - exploit validatable clauses\n",
    "    \n",
    "    clauses_added = True\n",
    "    new_F_prime = set(F_prime)\n",
    "\n",
    "    while(clauses_added):\n",
    "        ext2_F_prime = extension2(cnf_clauses, new_F_prime, random_assignment)\n",
    "        ppprint({\"new_F_prime\" : new_F_prime,\n",
    "                 \"ext2_F_prime\":ext2_F_prime,\n",
    "                 \"cnf_clauses\": cnf_clauses\n",
    "                  })\n",
    "        clauses_added = ext2_F_prime > new_F_prime\n",
    "        new_F_prime = set(ext2_F_prime)\n",
    "        \n",
    "    return new_F_prime\n",
    "\n",
    "def extension3(cnf_clauses, F_prime, random_assignment = True):\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "        Repeatedly apply extension 2 until there is no more progress\n",
    "        Propagate as much as possible\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    new_F_prime = set(F_prime)\n",
    "    \n",
    "    # Step 1 : clauses with unique literals\n",
    "    # clauses with 1 literal \n",
    "    unique_literal_validated_clauses = {index for index in new_F_prime if len(cnf_clauses[index]) == 1}\n",
    "    unique_literals = {cnf_clauses[index][0] for index in unique_literal_validated_clauses}\n",
    "    \n",
    "    # all cl\n",
    "    all_validated_clauses = set()\n",
    "    \n",
    "    for literal in unique_literals:\n",
    "        \n",
    "    \n",
    "    \n",
    "    remaining_validated_clauses = new_F_prime  - \n",
    "    \n",
    "    return new_F_prime\n",
    "\n",
    "\n",
    "input_cnf_clauses = [\n",
    "    [1],\n",
    "    [2, 3, 5],\n",
    "    [3, 6, 7, -8],\n",
    "    [3, 6],\n",
    "    [5, 9],\n",
    "    [2, -7],\n",
    "    [-4, -1],\n",
    "    [-4],\n",
    "    [-4, -8]\n",
    "]\n",
    "input_F_prime = {0, 7}\n",
    "\n",
    "expected_output = {0, 2, 3, 4, 5}\n",
    "\n",
    "ext1_F_prime = extension3(input_cnf_clauses, input_F_prime)\n",
    "\n",
    "def extension4(cnf_clauses, F_prime):\n",
    "    return F_prime\n",
    "    \n",
    "def grow(clauses, F_prime, extensions = None):\n",
    "    \"\"\"\n",
    "    \n",
    "        Procedure to efficiently grow the list clauses in ``F_prime``. The complement of F_prime is a correction\n",
    "        set. \n",
    "    \n",
    "        :param cnf_clauses: a collection of clauses (list of literals).\n",
    "        :param F_prime: hitting set : a list of clauses.\n",
    "        :param extensions: list of extensions activated\n",
    "        \n",
    "        The ``extensions`` argument is a list of extensions on the default grow procedure to optimize\n",
    "        the building of the minimum correction set. \n",
    "\n",
    "\n",
    "        :type cnf_clauses: iterable(iterable(int))\n",
    "        :type F_prime: iterable(int)\n",
    "        :type extensions: iterable(int)\n",
    "\n",
    "        Extension 1 : \n",
    "            \n",
    "            add all clauses that are true based on the assignment by the model of Fprime\n",
    "\n",
    "        Extension 2 : \n",
    "        \n",
    "            for all variables not in variables assigned by model of Fprime\n",
    "            give random values => manually check wether any clause is satisfied by this and\n",
    "            add it to Fprime.\n",
    "\n",
    "        Extension 3: \n",
    "            \n",
    "            greedy\n",
    "\n",
    "        Extension 4: \n",
    "            \n",
    "            Maxsat\n",
    "    \"\"\"\n",
    "    if not extensions: \n",
    "        return complement(clauses, F_prime)\n",
    "    \n",
    "    exts = {\n",
    "        0 : default_extension,\n",
    "        1 : extension1,\n",
    "        2 : extension2,\n",
    "        3 : extension2optimized,\n",
    "        4 : extension3,\n",
    "        5 : extension4\n",
    "    }\n",
    "    \n",
    "    assert all([True if ext in exts else False for ext in extensions]), \"extension doest not exist\"\n",
    "    \n",
    "    for ext in extensions:\n",
    "        F_prime = exts[ext](clauses, F_prime)\n",
    "        \n",
    "    return complement(clauses, F_prime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing flatten set\n",
      "Everything passed\n"
     ]
    }
   ],
   "source": [
    "run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMUS algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omus(cnf: CNF):    \n",
    "    clauses = cnf.clauses\n",
    "    weights = clauses_weights(clauses)\n",
    "    H = [] # the complement of a max-sat call\n",
    "\n",
    "    while(True):\n",
    "        # compute optimal hitting set\n",
    "        h = optimalHittingSet(H, weights)\n",
    "        \n",
    "        # set with all unique clauses from hitting set\n",
    "        F_prime = {i for i, hi in enumerate(h) if hi > 0}\n",
    "\n",
    "        # check satisfiability of clauses\n",
    "        if not checkSatClauses(clauses, F_prime):\n",
    "            return F_prime\n",
    "        \n",
    "        # add all clauses ny building complement\n",
    "        C = grow(clauses, F_prime, extensions=[3])\n",
    "        \n",
    "        if C in H:\n",
    "            raise \"MCS is already in H'\"\n",
    "        \n",
    "        H.append(C)\n",
    "        # printing        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toy example\n",
    "smus_cnf = smus_CNF()\n",
    "omus(smus_cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNf Files \n",
    "# cnfs = sorted(cnfUnsatInstances(), key=lambda item: item.stat().st_size)\n",
    "# c = cnfs[1]\n",
    "# cnf = CNF(from_file=c)\n",
    "# print(cnf.clauses)\n",
    "# omus(cnf)\n",
    "#for c in cnfs:\n",
    "#    cnf = CNF(from_file=c)\n",
    "#    o = omus(cnf)\n",
    "#    print(c, c.stat().st_size)\n",
    "#    print(cnf.clauses)\n",
    "\n",
    "# useless to call mus on cnf files, only on WCNF\n",
    "#for cnf_name, cnf_dict in cnfs.items():\n",
    "#    wcnf = CNF(from_file = cnf_dict['path']).weighted()\n",
    "#    with MUSX(wcnf, verbosity=1) as musx:\n",
    "#        print(musx.compute())\n",
    "#wncf = WCNF(from_file = cnf1['path'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
