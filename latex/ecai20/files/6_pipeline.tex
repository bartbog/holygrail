% Description of our pipeline, including the NLP part (though not fully automated):
% Can include Jens' table on challenges for BOS even with fully correct lexicon (from his poster).
% TODO : add ZebraTutor in Latex logic Mode
We developed a demo system, called \ourtool, named after Einstein's zebra puzzle, which is an integrated solution for solving logic grid puzzles, and for explaining in a human-understandable way how the solution can be obtained from the clues. 
The input to \ourtool is a plain English language representation of the clues and a list of all the \textit{entities} present in the puzzle. It then applies NLP techniques to build a puzzle-specific lexicon. This lexicon is fed into a type-aware variant of the semantical framework of Blackburn \& Bos \cite{Blackburn2005,Blackburn2006}, which translates the clues into Discourse Representation Theory \cite{DRT}. The logic is further transformed to a specification in the \idp language, a typed extension of first-order logic. 

The underlying solver, \idp\cite{idp} uses this formal representation of the clues both to solve the puzzle and to explain the solution. 
The complete specification undergoes the following \textbf{steps}:
% Pipeline description of the steps form start to end
% \paragraph{Steps} Our framework consists of the following steps, starting from the input:
\begin{compactenum}
  %\setlength\itemsep{-0.2em} -->Editors do not like this. 
	\item[A] Part-Of-Speech (POS) tagging: A part-of-speech tag is associated with each word using an out-of-the-box POS tagger \cite{DBLP:journals/coling/MarcusSM94}.
	\item[B] Chunking and lexicon building: A problem-specific lexicon is constructed; in this lexicon, each word or set of words (chunk) is assigned a role, based on the POS tags. On top of these roles, we defined a puzzle-independent grammar in the Blackburn and Bos framework \cite{Blackburn2005,Blackburn2006}. The grammar was created based on 10 example training puzzles, and tested on 10 different puzzles to ensure genericity. 
	\item[C] Parsing: We use a typed variant of the Blackburn and Bos semantic framework to use the lexicon and grammar to derive a logical formulation of the clues in Discourse Representation Theory. The typed extension allows us to discover the case where different verbs are used as synonyms for the same inherent relation between two types, e.g. `$ate(person, pasta)$' and `$ordered(person, pasta)$'. The typed discourse representation theory is then translated into the \idp language and the bijectivity and transitivity constraints are automatically added. 
	\item[D] Explanation-producing search in \idp: this is the main contribution of this paper, as explained in Section~\ref{sec:expl-gen-prod}.
	\item[E] Visualisation of the explanation: all the $(E_i, S_i, N_i)$ explanation steps are visualized by means of a color-coded logic grid, where different colors are used to highlight the $E_i$ and $N_i$ cells, and where the constraints of $S_i$ are highlighted as well. Figure~\ref{fig:zebrascreen} shows an example.
\end{compactenum}

 An online demo of our system can be found on \url{http://bartbog.github.io/zebra}; there, examples of all the different steps are given. 

A more detailed explanation of steps B and C of the information pipeline can be found in \cite{msc/Claes17}. From a natural language processing point of view, the most difficult part is step B: automatically deriving the right lexicon. In our current system, this is a semi-automated method that suggests a lexicon and lets a user modify and approve it once. The reason is 
that the current approach assumes the clues are written in controlled natural language that abides to the (generic) grammar rules. However, puzzle developers are often keen to craft seeming ambiguities (reusing a verb for two relations, name ambiguations, use of gender to discriminate names), or add unnecessary words or contextual synonyms (e.g., using ``in the morning'', when there is only one timeslot before 12:00). In such case,  some manual intervention of the user is needed, either by extending the lexicon to cover or by reformulating those sentences into the unambiguous controlled natural language.
\bart{Die uitleg gaat niet *echt* over lexicon, maar ook over ``ochtend'' wat meer background knowledge is... }
% \item Our explanation generation step assumes a consistent theory. If one of the clues is missing or wrong, it would be unable to completely solve the puzzle as the resulting $I_n$ would not match the intended puzzle solution.
% \end{inparaenum}
%  \bart{Die twee redenen die hier staan... Hebben die iets met de chunking te maken? De laatste is niet echt een geldige reden. Ik zou die weglaten (uiteraard genereert onze searc h niet de juiste explanations als het foute input krijgt. Maar het zal ook blijven 
